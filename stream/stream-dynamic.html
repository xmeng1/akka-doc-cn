<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
<title>Dynamic stream handling &bull; Akka Documentation 中文</title>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="description" content="akka-docs-cn"/>
<link rel="canonical" href="http://doc.akka.io/docs/akka/current/stream/stream-dynamic.html"/>
<script type="text/javascript" src="../lib/jquery/jquery.min.js"></script>
<script type="text/javascript" src="../lib/foundation/dist/js/foundation.min.js"></script>
<link rel="stylesheet" type="text/css" href="../lib/normalize.css/normalize.css"/>
<link rel="stylesheet" type="text/css" href="../lib/foundation/dist/css/foundation.min.css"/>
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.css" />
<link rel="stylesheet" type="text/css" href="../css/icons.css"/>
<link rel="stylesheet" type="text/css" href="../css/page.css"/>
<link rel="shortcut icon" href="../images/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="../images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../images/favicon-16x16.png">
<link rel="manifest" href="../images/manifest.json">
<meta name="msapplication-TileImage" content="../images/mstile-150x150.png">
<meta name="msapplication-TileColor" content="#15a9ce">
<meta name="theme-color" content="#15a9ce">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) start -->
<script src="https://optanon.blob.core.windows.net/consent/159bb13d-6748-4399-806e-ac28db879785.js" type="text/javascript" charset="UTF-8"></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) end -->
<!--Google Analytics-->
<script type="text/plain" class="optanon-category-2">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-21117439-1']);
_gaq.push(['_setDomainName', 'akka.io']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})()
</script>
<script type="text/plain" class="optanon-category-2">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-23127719-1', 'lightbend.com', {'allowLinker': true, 'name': 'tsTracker'});
ga('tsTracker.require', 'linker');
ga('tsTracker.linker:autoLink', ['lightbend.com','playframework.com','scala-lang.org','scaladays.org','spray.io','akka.io','scala-sbt.org','scala-ide.org']);
ga('tsTracker.send', 'pageview');
</script>
<!--Marketo-->
<script type="text/plain" class="optanon-category-3">
(function() {
var didInit = false;
function initMunchkin() {
if(didInit === false) {
didInit = true;
Munchkin.init('558-NCX-702', { 'asyncOnly': true, 'disableClickDelay': true });
}
}
var s = document.createElement('script');
s.type = 'text/javascript';
s.async = true;
s.src = '//munchkin.marketo.net/munchkin.js';
s.onreadystatechange = function() {
if (this.readyState == 'complete' || this.readyState == 'loaded') {
initMunchkin();
}
};
s.onload = initMunchkin;
document.getElementsByTagName('head')[0].appendChild(s);
})();
</script>
</head>

<body id="underlay" data-toggler="nav-open">

<header class="site-header hide-for-large">
<div class="sticky-header clearfix">
<a href="http://akka.io"><img class="logo" src="../images/akka-logo-reverse.svg"></a>

<button class="menu-icon float-right" type="button" data-toggle="underlay overlay"></button>
</div>
<div id="overlay" class="overlay-nav" data-toggler="nav-open">
<header class="nav-header">
<div class="nav-header-title">
<h1><a href="../index.html">Akka Documentation 中文</a></h1>
</div>
<div class="nav-header-version">
Version 2.5-SNAPSHOT
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-scala">Scala</option><option class="group" value="group-java">Java</option></select>
</div>
<div id="overlay-search-container" class="nav-header-search">
<input id="overlay-search" type="search" class="search" placeholder="Search"/>
</div>
</header>
<nav class="nav-toc">
<ul>
  <li><a href="../security/index.html" class="page">Security Announcements</a></li>
  <li><a href="../guide/index.html" class="page">Getting Started Guide</a></li>
  <li><a href="../general/index.html" class="page">General Concepts</a></li>
  <li><a href="../index-actors.html" class="page">Actors</a></li>
  <li><a href="../typed/index.html" class="page">Akka Typed</a></li>
  <li><a href="../index-cluster.html" class="page">Clustering</a></li>
  <li><a href="../stream/index.html" class="page">Streams</a>
  <ul>
    <li><a href="../stream/index.html#dependency" class="header">Dependency</a></li>
    <li><a href="../stream/stream-introduction.html" class="page">Introduction</a></li>
    <li><a href="../stream/stream-quickstart.html" class="page">Streams Quickstart Guide</a></li>
    <li><a href="../general/stream/stream-design.html" class="page">Design Principles behind Akka Streams</a></li>
    <li><a href="../stream/stream-flows-and-basics.html" class="page">Basics and working with Flows</a></li>
    <li><a href="../stream/stream-graphs.html" class="page">Working with Graphs</a></li>
    <li><a href="../stream/stream-composition.html" class="page">Modularity, Composition and Hierarchy</a></li>
    <li><a href="../stream/stream-rate.html" class="page">Buffers and working with rate</a></li>
    <li><a href="../stream/stream-dynamic.html#dynamic-stream-handling" class="active page">Dynamic stream handling</a>
    <ul>
      <li><a href="../stream/stream-dynamic.html#dependency" class="header">Dependency</a></li>
      <li><a href="../stream/stream-dynamic.html#introduction" class="header">Introduction</a></li>
      <li><a href="../stream/stream-dynamic.html#controlling-stream-completion-with-killswitch" class="header">Controlling stream completion with KillSwitch</a></li>
      <li><a href="../stream/stream-dynamic.html#dynamic-fan-in-and-fan-out-with-mergehub-broadcasthub-and-partitionhub" class="header">Dynamic fan-in and fan-out with MergeHub, BroadcastHub and PartitionHub</a></li>
    </ul></li>
    <li><a href="../stream/stream-customize.html" class="page">Custom stream processing</a></li>
    <li><a href="../stream/stream-integrations.html" class="page">Integration</a></li>
    <li><a href="../stream/stream-error.html" class="page">Error Handling in Streams</a></li>
    <li><a href="../stream/stream-io.html" class="page">Working with streaming IO</a></li>
    <li><a href="../stream/stream-refs.html" class="page">StreamRefs - Reactive Streams over the network</a></li>
    <li><a href="../stream/stream-parallelism.html" class="page">Pipelining and Parallelism</a></li>
    <li><a href="../stream/stream-testkit.html" class="page">Testing streams</a></li>
    <li><a href="../stream/stream-substream.html" class="page">Substreams</a></li>
    <li><a href="../stream/stream-cookbook.html" class="page">Streams Cookbook</a></li>
    <li><a href="../general/stream/stream-configuration.html" class="page">Configuration</a></li>
    <li><a href="../stream/operators/index.html" class="page">Operators</a></li>
  </ul></li>
  <li><a href="../index-network.html" class="page">Networking</a></li>
  <li><a href="../discovery/index.html" class="page">Discovery</a></li>
  <li><a href="../index-futures.html" class="page">Futures and Agents</a></li>
  <li><a href="../index-utilities.html" class="page">Utilities</a></li>
  <li><a href="../common/other-modules.html" class="page">Other Akka modules</a></li>
  <li><a href="../howto.html" class="page">HowTo: Common Patterns</a></li>
  <li><a href="../project/index.html" class="page">Project Information</a></li>
  <li><a href="../additional/index.html" class="page">Additional Information</a></li>
  <li><a href="../chinese/index.html" class="page">中文版文档说明</a></li>
</ul>
</nav>
</div>
</header>

<aside class="show-for-large">
<header class="nav-header fixed-sidebar-header">
<div class="nav-header-title">
<h1><a href="../index.html">Akka Documentation 中文</a></h1>
</div>
<div class="nav-header-version">
Version 2.5-SNAPSHOT
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-scala">Scala</option><option class="group" value="group-java">Java</option></select>
</div>
<div class="nav-header-search">
<input id="search" type="search" class="search" placeholder="Search"/>
</div>
</header>
<nav class="site-nav fixed-sidebar-contents">
<div class="nav-toc">
<ul>
  <li><a href="../security/index.html" class="page">Security Announcements</a></li>
  <li><a href="../guide/index.html" class="page">Getting Started Guide</a></li>
  <li><a href="../general/index.html" class="page">General Concepts</a></li>
  <li><a href="../index-actors.html" class="page">Actors</a></li>
  <li><a href="../typed/index.html" class="page">Akka Typed</a></li>
  <li><a href="../index-cluster.html" class="page">Clustering</a></li>
  <li><a href="../stream/index.html" class="page">Streams</a>
  <ul>
    <li><a href="../stream/index.html#dependency" class="header">Dependency</a></li>
    <li><a href="../stream/stream-introduction.html" class="page">Introduction</a></li>
    <li><a href="../stream/stream-quickstart.html" class="page">Streams Quickstart Guide</a></li>
    <li><a href="../general/stream/stream-design.html" class="page">Design Principles behind Akka Streams</a></li>
    <li><a href="../stream/stream-flows-and-basics.html" class="page">Basics and working with Flows</a></li>
    <li><a href="../stream/stream-graphs.html" class="page">Working with Graphs</a></li>
    <li><a href="../stream/stream-composition.html" class="page">Modularity, Composition and Hierarchy</a></li>
    <li><a href="../stream/stream-rate.html" class="page">Buffers and working with rate</a></li>
    <li><a href="../stream/stream-dynamic.html#dynamic-stream-handling" class="active page">Dynamic stream handling</a>
    <ul>
      <li><a href="../stream/stream-dynamic.html#dependency" class="header">Dependency</a></li>
      <li><a href="../stream/stream-dynamic.html#introduction" class="header">Introduction</a></li>
      <li><a href="../stream/stream-dynamic.html#controlling-stream-completion-with-killswitch" class="header">Controlling stream completion with KillSwitch</a></li>
      <li><a href="../stream/stream-dynamic.html#dynamic-fan-in-and-fan-out-with-mergehub-broadcasthub-and-partitionhub" class="header">Dynamic fan-in and fan-out with MergeHub, BroadcastHub and PartitionHub</a></li>
    </ul></li>
    <li><a href="../stream/stream-customize.html" class="page">Custom stream processing</a></li>
    <li><a href="../stream/stream-integrations.html" class="page">Integration</a></li>
    <li><a href="../stream/stream-error.html" class="page">Error Handling in Streams</a></li>
    <li><a href="../stream/stream-io.html" class="page">Working with streaming IO</a></li>
    <li><a href="../stream/stream-refs.html" class="page">StreamRefs - Reactive Streams over the network</a></li>
    <li><a href="../stream/stream-parallelism.html" class="page">Pipelining and Parallelism</a></li>
    <li><a href="../stream/stream-testkit.html" class="page">Testing streams</a></li>
    <li><a href="../stream/stream-substream.html" class="page">Substreams</a></li>
    <li><a href="../stream/stream-cookbook.html" class="page">Streams Cookbook</a></li>
    <li><a href="../general/stream/stream-configuration.html" class="page">Configuration</a></li>
    <li><a href="../stream/operators/index.html" class="page">Operators</a></li>
  </ul></li>
  <li><a href="../index-network.html" class="page">Networking</a></li>
  <li><a href="../discovery/index.html" class="page">Discovery</a></li>
  <li><a href="../index-futures.html" class="page">Futures and Agents</a></li>
  <li><a href="../index-utilities.html" class="page">Utilities</a></li>
  <li><a href="../common/other-modules.html" class="page">Other Akka modules</a></li>
  <li><a href="../howto.html" class="page">HowTo: Common Patterns</a></li>
  <li><a href="../project/index.html" class="page">Project Information</a></li>
  <li><a href="../additional/index.html" class="page">Additional Information</a></li>
  <li><a href="../chinese/index.html" class="page">中文版文档说明</a></li>
</ul>
</div>
</nav>
<footer class="nav-footer fixed-sidebar-footer">
<a href="http://akka.io"><img class="logo" src="../images/akka-logo-reverse.svg"></a>

</footer>
</aside>

<main class="fixed-shift-for-large expanded row">
<section class="site-content small-12 column">

<article class="page-content row">
<div class="small-12 large-9 column" id="docs">
<h1><a href="#dynamic-stream-handling" name="dynamic-stream-handling" class="anchor"><span class="anchor-link"></span></a>Dynamic stream handling</h1>
<h2><a href="#dependency" name="dependency" class="anchor"><span class="anchor-link"></span></a>Dependency</h2>
<p>To use Akka Streams, add the module to your project:</p><dl class="dependency"><dt>sbt</dt><dd><pre class="prettyprint"><code class="language-scala">libraryDependencies += "com.typesafe.akka" %% "akka-stream" % "2.5-SNAPSHOT"</code></pre></dd><dt>Maven</dt><dd><pre class="prettyprint"><code class="language-xml">&lt;dependency&gt;
  &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt;
  &lt;artifactId&gt;akka-stream_2.12&lt;/artifactId&gt;
  &lt;version&gt;2.5-SNAPSHOT&lt;/version&gt;
&lt;/dependency&gt;</code></pre></dd><dt>Gradle</dt><dd><pre class="prettyprint"><code class="language-gradle">dependencies {
  compile group: 'com.typesafe.akka', name: 'akka-stream_2.12', version: '2.5-SNAPSHOT'
}</code></pre></dd></dl>
<h2><a href="#introduction" name="introduction" class="anchor"><span class="anchor-link"></span></a>Introduction</h2>
<a id="kill-switch"></a>
<h2><a href="#controlling-stream-completion-with-killswitch" name="controlling-stream-completion-with-killswitch" class="anchor"><span class="anchor-link"></span></a>Controlling stream completion with KillSwitch</h2>
<p>A <code>KillSwitch</code> allows the completion of operators of <code>FlowShape</code> from the outside. It consists of a flow element that can be linked to an operator of <code>FlowShape</code> needing completion control. The <code>KillSwitch</code> <span class="group-scala">trait</span> <span class="group-java">interface</span> allows to:</p>
<ul>
  <li>complete the stream(s) via <code>shutdown()</code></li>
  <li>fail the stream(s) via <code>abort(Throwable error)</code></li>
</ul>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-stream/src/main/scala/akka/stream/KillSwitch.scala#L140-L149" target="_blank" title="Go to snippet source"></a><code class="language-scala">trait KillSwitch {
  /**
   * After calling [[KillSwitch#shutdown()]] the linked [[Graph]]s of [[FlowShape]] are completed normally.
   */
  def shutdown(): Unit
  /**
   * After calling [[KillSwitch#abort()]] the linked [[Graph]]s of [[FlowShape]] are failed.
   */
  def abort(ex: Throwable): Unit
}</code></pre></dd>
</dl>
<p>After the first call to either <code>shutdown</code> or <code>abort</code>, all subsequent calls to any of these methods will be ignored. Stream completion is performed by both</p>
<ul>
  <li>cancelling its upstream.</li>
  <li>completing (in case of <code>shutdown</code>) or failing (in case of <code>abort</code>) its downstream</li>
</ul>
<p>A <code>KillSwitch</code> can control the completion of one or multiple streams, and therefore comes in two different flavours.</p>
<a id="unique-kill-switch"></a>
<h3><a href="#uniquekillswitch" name="uniquekillswitch" class="anchor"><span class="anchor-link"></span></a>UniqueKillSwitch</h3>
<p><code>UniqueKillSwitch</code> allows to control the completion of <strong>one</strong> materialized <code>Graph</code> of <code>FlowShape</code>. Refer to the below for usage examples.</p>
<ul>
  <li><strong>Shutdown</strong></li>
</ul>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/KillSwitchDocSpec.scala#L25-L37" target="_blank" title="Go to snippet source"></a><code class="language-scala">val countingSrc = Source(Stream.from(1)).delay(1.second, DelayOverflowStrategy.backpressure)
val lastSnk = Sink.last[Int]

val (killSwitch, last) = countingSrc
  .viaMat(KillSwitches.single)(Keep.right)
  .toMat(lastSnk)(Keep.both)
  .run()

doSomethingElse()

killSwitch.shutdown()

Await.result(last, 1.second) shouldBe 2</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/KillSwitchDocTest.java#L52-L70" target="_blank" title="Go to snippet source"></a><code class="language-java">final Source&lt;Integer, NotUsed&gt; countingSrc =
    Source.from(new ArrayList&lt;&gt;(Arrays.asList(1, 2, 3, 4)))
        .delay(Duration.ofSeconds(1), DelayOverflowStrategy.backpressure());
final Sink&lt;Integer, CompletionStage&lt;Integer&gt;&gt; lastSnk = Sink.last();

final Pair&lt;UniqueKillSwitch, CompletionStage&lt;Integer&gt;&gt; stream =
    countingSrc
        .viaMat(KillSwitches.single(), Keep.right())
        .toMat(lastSnk, Keep.both())
        .run(mat);

final UniqueKillSwitch killSwitch = stream.first();
final CompletionStage&lt;Integer&gt; completionStage = stream.second();

doSomethingElse();
killSwitch.shutdown();

final int finalCount = completionStage.toCompletableFuture().get(1, TimeUnit.SECONDS);
assertEquals(2, finalCount);</code></pre></dd>
</dl>
<ul>
  <li><strong>Abort</strong></li>
</ul>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/KillSwitchDocSpec.scala#L46-L56" target="_blank" title="Go to snippet source"></a><code class="language-scala">val countingSrc = Source(Stream.from(1)).delay(1.second, DelayOverflowStrategy.backpressure)
val lastSnk = Sink.last[Int]

val (killSwitch, last) = countingSrc
  .viaMat(KillSwitches.single)(Keep.right)
  .toMat(lastSnk)(Keep.both).run()

val error = new RuntimeException(&quot;boom!&quot;)
killSwitch.abort(error)

Await.result(last.failed, 1.second) shouldBe error</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/KillSwitchDocTest.java#L76-L95" target="_blank" title="Go to snippet source"></a><code class="language-java">final Source&lt;Integer, NotUsed&gt; countingSrc =
    Source.from(new ArrayList&lt;&gt;(Arrays.asList(1, 2, 3, 4)))
        .delay(Duration.ofSeconds(1), DelayOverflowStrategy.backpressure());
final Sink&lt;Integer, CompletionStage&lt;Integer&gt;&gt; lastSnk = Sink.last();

final Pair&lt;UniqueKillSwitch, CompletionStage&lt;Integer&gt;&gt; stream =
    countingSrc
        .viaMat(KillSwitches.single(), Keep.right())
        .toMat(lastSnk, Keep.both())
        .run(mat);

final UniqueKillSwitch killSwitch = stream.first();
final CompletionStage&lt;Integer&gt; completionStage = stream.second();

final Exception error = new Exception(&quot;boom!&quot;);
killSwitch.abort(error);

final int result =
    completionStage.toCompletableFuture().exceptionally(e -&gt; -1).get(1, TimeUnit.SECONDS);
assertEquals(-1, result);</code></pre></dd>
</dl>
<a id="shared-kill-switch"></a>
<h3><a href="#sharedkillswitch" name="sharedkillswitch" class="anchor"><span class="anchor-link"></span></a>SharedKillSwitch</h3>
<p>A <code>SharedKillSwitch</code> allows to control the completion of an arbitrary number operators of <code>FlowShape</code>. It can be materialized multiple times via its <code>flow</code> method, and all materialized operators linked to it are controlled by the switch. Refer to the below for usage examples.</p>
<ul>
  <li><strong>Shutdown</strong></li>
</ul>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/KillSwitchDocSpec.scala#L67-L85" target="_blank" title="Go to snippet source"></a><code class="language-scala">val countingSrc = Source(Stream.from(1)).delay(1.second, DelayOverflowStrategy.backpressure)
val lastSnk = Sink.last[Int]
val sharedKillSwitch = KillSwitches.shared(&quot;my-kill-switch&quot;)

val last = countingSrc
  .via(sharedKillSwitch.flow)
  .runWith(lastSnk)

val delayedLast = countingSrc
  .delay(1.second, DelayOverflowStrategy.backpressure)
  .via(sharedKillSwitch.flow)
  .runWith(lastSnk)

doSomethingElse()

sharedKillSwitch.shutdown()

Await.result(last, 1.second) shouldBe 2
Await.result(delayedLast, 1.second) shouldBe 1</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/KillSwitchDocTest.java#L101-L124" target="_blank" title="Go to snippet source"></a><code class="language-java">final Source&lt;Integer, NotUsed&gt; countingSrc =
    Source.from(new ArrayList&lt;&gt;(Arrays.asList(1, 2, 3, 4)))
        .delay(Duration.ofSeconds(1), DelayOverflowStrategy.backpressure());
final Sink&lt;Integer, CompletionStage&lt;Integer&gt;&gt; lastSnk = Sink.last();
final SharedKillSwitch killSwitch = KillSwitches.shared(&quot;my-kill-switch&quot;);

final CompletionStage&lt;Integer&gt; completionStage =
    countingSrc.viaMat(killSwitch.flow(), Keep.right()).toMat(lastSnk, Keep.right()).run(mat);
final CompletionStage&lt;Integer&gt; completionStageDelayed =
    countingSrc
        .delay(Duration.ofSeconds(1), DelayOverflowStrategy.backpressure())
        .viaMat(killSwitch.flow(), Keep.right())
        .toMat(lastSnk, Keep.right())
        .run(mat);

doSomethingElse();
killSwitch.shutdown();

final int finalCount = completionStage.toCompletableFuture().get(1, TimeUnit.SECONDS);
final int finalCountDelayed =
    completionStageDelayed.toCompletableFuture().get(1, TimeUnit.SECONDS);

assertEquals(2, finalCount);
assertEquals(1, finalCountDelayed);</code></pre></dd>
</dl>
<ul>
  <li><strong>Abort</strong></li>
</ul>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/KillSwitchDocSpec.scala#L94-L105" target="_blank" title="Go to snippet source"></a><code class="language-scala">val countingSrc = Source(Stream.from(1)).delay(1.second)
val lastSnk = Sink.last[Int]
val sharedKillSwitch = KillSwitches.shared(&quot;my-kill-switch&quot;)

val last1 = countingSrc.via(sharedKillSwitch.flow).runWith(lastSnk)
val last2 = countingSrc.via(sharedKillSwitch.flow).runWith(lastSnk)

val error = new RuntimeException(&quot;boom!&quot;)
sharedKillSwitch.abort(error)

Await.result(last1.failed, 1.second) shouldBe error
Await.result(last2.failed, 1.second) shouldBe error</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/KillSwitchDocTest.java#L130-L150" target="_blank" title="Go to snippet source"></a><code class="language-java">final Source&lt;Integer, NotUsed&gt; countingSrc =
    Source.from(new ArrayList&lt;&gt;(Arrays.asList(1, 2, 3, 4)))
        .delay(Duration.ofSeconds(1), DelayOverflowStrategy.backpressure());
final Sink&lt;Integer, CompletionStage&lt;Integer&gt;&gt; lastSnk = Sink.last();
final SharedKillSwitch killSwitch = KillSwitches.shared(&quot;my-kill-switch&quot;);

final CompletionStage&lt;Integer&gt; completionStage1 =
    countingSrc.viaMat(killSwitch.flow(), Keep.right()).toMat(lastSnk, Keep.right()).run(mat);
final CompletionStage&lt;Integer&gt; completionStage2 =
    countingSrc.viaMat(killSwitch.flow(), Keep.right()).toMat(lastSnk, Keep.right()).run(mat);

final Exception error = new Exception(&quot;boom!&quot;);
killSwitch.abort(error);

final int result1 =
    completionStage1.toCompletableFuture().exceptionally(e -&gt; -1).get(1, TimeUnit.SECONDS);
final int result2 =
    completionStage2.toCompletableFuture().exceptionally(e -&gt; -1).get(1, TimeUnit.SECONDS);

assertEquals(-1, result1);
assertEquals(-1, result2);</code></pre></dd>
</dl><div class="callout note "><div class="callout-title">Note</div>
<p>A <code>UniqueKillSwitch</code> is always a result of a materialization, whilst <code>SharedKillSwitch</code> needs to be constructed before any materialization takes place.</p></div>
<h2><a href="#dynamic-fan-in-and-fan-out-with-mergehub-broadcasthub-and-partitionhub" name="dynamic-fan-in-and-fan-out-with-mergehub-broadcasthub-and-partitionhub" class="anchor"><span class="anchor-link"></span></a>Dynamic fan-in and fan-out with MergeHub, BroadcastHub and PartitionHub</h2>
<p>There are many cases when consumers or producers of a certain service (represented as a Sink, Source, or possibly Flow) are dynamic and not known in advance. The Graph DSL does not allow to represent this, all connections of the graph must be known in advance and must be connected upfront. To allow dynamic fan-in and fan-out streaming, the Hubs should be used. They provide means to construct <code>Sink</code> and <code>Source</code> pairs that are &ldquo;attached&rdquo; to each other, but one of them can be materialized multiple times to implement dynamic fan-in or fan-out.</p>
<h3><a href="#using-the-mergehub" name="using-the-mergehub" class="anchor"><span class="anchor-link"></span></a>Using the MergeHub</h3>
<p>A <code>MergeHub</code> allows to implement a dynamic fan-in junction point in a graph where elements coming from different producers are emitted in a First-Comes-First-Served fashion. If the consumer cannot keep up then <em>all</em> of the producers are backpressured. The hub itself comes as a <code>Source</code> to which the single consumer can be attached. It is not possible to attach any producers until this <code>Source</code> has been materialized (started). This is ensured by the fact that we only get the corresponding <code>Sink</code> as a materialized value. Usage might look like this:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/HubsDocSpec.scala#L25-L41" target="_blank" title="Go to snippet source"></a><code class="language-scala">// A simple consumer that will print to the console for now
val consumer = Sink.foreach(println)

// Attach a MergeHub Source to the consumer. This will materialize to a
// corresponding Sink.
val runnableGraph: RunnableGraph[Sink[String, NotUsed]] =
  MergeHub.source[String](perProducerBufferSize = 16).to(consumer)

// By running/materializing the consumer we get back a Sink, and hence
// now have access to feed elements into it. This Sink can be materialized
// any number of times, and every element that enters the Sink will
// be consumed by our consumer.
val toConsumer: Sink[String, NotUsed] = runnableGraph.run()

// Feeding two independent sources into the hub.
Source.single(&quot;Hello!&quot;).runWith(toConsumer)
Source.single(&quot;Hub!&quot;).runWith(toConsumer)</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/HubDocTest.java#L47-L61" target="_blank" title="Go to snippet source"></a><code class="language-java">// A simple consumer that will print to the console for now
Sink&lt;String, CompletionStage&lt;Done&gt;&gt; consumer = Sink.foreach(System.out::println);

// Attach a MergeHub Source to the consumer. This will materialize to a
// corresponding Sink.
RunnableGraph&lt;Sink&lt;String, NotUsed&gt;&gt; runnableGraph = MergeHub.of(String.class, 16).to(consumer);

// By running/materializing the consumer we get back a Sink, and hence
// now have access to feed elements into it. This Sink can be materialized
// any number of times, and every element that enters the Sink will
// be consumed by our consumer.
Sink&lt;String, NotUsed&gt; toConsumer = runnableGraph.run(materializer);

Source.single(&quot;Hello!&quot;).runWith(toConsumer, materializer);
Source.single(&quot;Hub!&quot;).runWith(toConsumer, materializer);</code></pre></dd>
</dl>
<p>This sequence, while might look odd at first, ensures proper startup order. Once we get the <code>Sink</code>, we can use it as many times as wanted. Everything that is fed to it will be delivered to the consumer we attached previously until it cancels.</p>
<h3><a href="#using-the-broadcasthub" name="using-the-broadcasthub" class="anchor"><span class="anchor-link"></span></a>Using the BroadcastHub</h3>
<p>A <code>BroadcastHub</code> can be used to consume elements from a common producer by a dynamic set of consumers. The rate of the producer will be automatically adapted to the slowest consumer. In this case, the hub is a <code>Sink</code> to which the single producer must be attached first. Consumers can only be attached once the <code>Sink</code> has been materialized (i.e. the producer has been started). One example of using the <code>BroadcastHub</code>:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/HubsDocSpec.scala#L49-L65" target="_blank" title="Go to snippet source"></a><code class="language-scala">// A simple producer that publishes a new &quot;message&quot; every second
val producer = Source.tick(1.second, 1.second, &quot;New message&quot;)

// Attach a BroadcastHub Sink to the producer. This will materialize to a
// corresponding Source.
// (We need to use toMat and Keep.right since by default the materialized
// value to the left is used)
val runnableGraph: RunnableGraph[Source[String, NotUsed]] =
  producer.toMat(BroadcastHub.sink(bufferSize = 256))(Keep.right)

// By running/materializing the producer, we get back a Source, which
// gives us access to the elements published by the producer.
val fromProducer: Source[String, NotUsed] = runnableGraph.run()

// Print out messages from the producer in two independent consumers
fromProducer.runForeach(msg ⇒ println(&quot;consumer1: &quot; + msg))
fromProducer.runForeach(msg ⇒ println(&quot;consumer2: &quot; + msg))</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/HubDocTest.java#L71-L88" target="_blank" title="Go to snippet source"></a><code class="language-java">// A simple producer that publishes a new &quot;message&quot; every second
Source&lt;String, Cancellable&gt; producer =
    Source.tick(Duration.ofSeconds(1), Duration.ofSeconds(1), &quot;New message&quot;);

// Attach a BroadcastHub Sink to the producer. This will materialize to a
// corresponding Source.
// (We need to use toMat and Keep.right since by default the materialized
// value to the left is used)
RunnableGraph&lt;Source&lt;String, NotUsed&gt;&gt; runnableGraph =
    producer.toMat(BroadcastHub.of(String.class, 256), Keep.right());

// By running/materializing the producer, we get back a Source, which
// gives us access to the elements published by the producer.
Source&lt;String, NotUsed&gt; fromProducer = runnableGraph.run(materializer);

// Print out messages from the producer in two independent consumers
fromProducer.runForeach(msg -&gt; System.out.println(&quot;consumer1: &quot; + msg), materializer);
fromProducer.runForeach(msg -&gt; System.out.println(&quot;consumer2: &quot; + msg), materializer);</code></pre></dd>
</dl>
<p>The resulting <code>Source</code> can be materialized any number of times, each materialization effectively attaching a new subscriber. If there are no subscribers attached to this hub then it will not drop any elements but instead backpressure the upstream producer until subscribers arrive. This behavior can be tweaked by using the operators <code>.buffer</code> for example with a drop strategy, or attaching a subscriber that drops all messages. If there are no other subscribers, this will ensure that the producer is kept drained (dropping all elements) and once a new subscriber arrives it will adaptively slow down, ensuring no more messages are dropped.</p>
<h3><a href="#combining-dynamic-operators-to-build-a-simple-publish-subscribe-service" name="combining-dynamic-operators-to-build-a-simple-publish-subscribe-service" class="anchor"><span class="anchor-link"></span></a>Combining dynamic operators to build a simple Publish-Subscribe service</h3>
<p>The features provided by the Hub implementations are limited by default. This is by design, as various combinations can be used to express additional features like unsubscribing producers or consumers externally. We show here an example that builds a <code>Flow</code> representing a publish-subscribe channel. The input of the <code>Flow</code> is published to all subscribers while the output streams all the elements published.</p>
<p>First, we connect a <code>MergeHub</code> and a <code>BroadcastHub</code> together to form a publish-subscribe channel. Once we materialize this small stream, we get back a pair of <code>Source</code> and <code>Sink</code> that together define the publish and subscribe sides of our channel.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/HubsDocSpec.scala#L73-L77" target="_blank" title="Go to snippet source"></a><code class="language-scala">// Obtain a Sink and Source which will publish and receive from the &quot;bus&quot; respectively.
val (sink, source) =
  MergeHub.source[String](perProducerBufferSize = 16)
    .toMat(BroadcastHub.sink(bufferSize = 256))(Keep.both)
    .run()</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/HubDocTest.java#L98-L105" target="_blank" title="Go to snippet source"></a><code class="language-java">// Obtain a Sink and Source which will publish and receive from the &quot;bus&quot; respectively.
Pair&lt;Sink&lt;String, NotUsed&gt;, Source&lt;String, NotUsed&gt;&gt; sinkAndSource =
    MergeHub.of(String.class, 16)
        .toMat(BroadcastHub.of(String.class, 256), Keep.both())
        .run(materializer);

Sink&lt;String, NotUsed&gt; sink = sinkAndSource.first();
Source&lt;String, NotUsed&gt; source = sinkAndSource.second();</code></pre></dd>
</dl>
<p>We now use a few tricks to add more features. First of all, we attach a <code>Sink.ignore</code> at the broadcast side of the channel to keep it drained when there are no subscribers. If this behavior is not the desired one this line can be dropped.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/HubsDocSpec.scala#L81-L84" target="_blank" title="Go to snippet source"></a><code class="language-scala">// Ensure that the Broadcast output is dropped if there are no listening parties.
// If this dropping Sink is not attached, then the broadcast hub will not drop any
// elements itself when there are no subscribers, backpressuring the producer instead.
source.runWith(Sink.ignore)</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/HubDocTest.java#L109-L112" target="_blank" title="Go to snippet source"></a><code class="language-java">// Ensure that the Broadcast output is dropped if there are no listening parties.
// If this dropping Sink is not attached, then the broadcast hub will not drop any
// elements itself when there are no subscribers, backpressuring the producer instead.
source.runWith(Sink.ignore(), materializer);</code></pre></dd>
</dl>
<p>We now wrap the <code>Sink</code> and <code>Source</code> in a <code>Flow</code> using <code>Flow.fromSinkAndSource</code>. This bundles up the two sides of the channel into one and forces users of it to always define a publisher and subscriber side (even if the subscriber side is dropping). It also allows us to attach a <code>KillSwitch</code> as a <code>BidiStage</code> which in turn makes it possible to close both the original <code>Sink</code> and <code>Source</code> at the same time. Finally, we add <code>backpressureTimeout</code> on the consumer side to ensure that subscribers that block the channel for more than 3 seconds are forcefully removed (and their stream failed).</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/HubsDocSpec.scala#L88-L94" target="_blank" title="Go to snippet source"></a><code class="language-scala">// We create now a Flow that represents a publish-subscribe channel using the above
// started stream as its &quot;topic&quot;. We add two more features, external cancellation of
// the registration and automatic cleanup for very slow subscribers.
val busFlow: Flow[String, String, UniqueKillSwitch] =
  Flow.fromSinkAndSource(sink, source)
    .joinMat(KillSwitches.singleBidi[String, String])(Keep.right)
    .backpressureTimeout(3.seconds)</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/HubDocTest.java#L116-L122" target="_blank" title="Go to snippet source"></a><code class="language-java">// We create now a Flow that represents a publish-subscribe channel using the above
// started stream as its &quot;topic&quot;. We add two more features, external cancellation of
// the registration and automatic cleanup for very slow subscribers.
Flow&lt;String, String, UniqueKillSwitch&gt; busFlow =
    Flow.fromSinkAndSource(sink, source)
        .joinMat(KillSwitches.singleBidi(), Keep.right())
        .backpressureTimeout(Duration.ofSeconds(1));</code></pre></dd>
</dl>
<p>The resulting Flow now has a type of <code>Flow[String, String, UniqueKillSwitch]</code> representing a publish-subscribe channel which can be used any number of times to attach new producers or consumers. In addition, it materializes to a <code>UniqueKillSwitch</code> (see <a href="#unique-kill-switch">UniqueKillSwitch</a>) that can be used to deregister a single user externally:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/HubsDocSpec.scala#L98-L105" target="_blank" title="Go to snippet source"></a><code class="language-scala">val switch: UniqueKillSwitch =
  Source.repeat(&quot;Hello world!&quot;)
    .viaMat(busFlow)(Keep.right)
    .to(Sink.foreach(println))
    .run()

// Shut down externally
switch.shutdown()</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/HubDocTest.java#L126-L133" target="_blank" title="Go to snippet source"></a><code class="language-java">UniqueKillSwitch killSwitch =
    Source.repeat(&quot;Hello World!&quot;)
        .viaMat(busFlow, Keep.right())
        .to(Sink.foreach(System.out::println))
        .run(materializer);

// Shut down externally
killSwitch.shutdown();</code></pre></dd>
</dl>
<h3><a href="#using-the-partitionhub" name="using-the-partitionhub" class="anchor"><span class="anchor-link"></span></a>Using the PartitionHub</h3>
<p><strong>This is a <a href="../common/may-change.html">may change</a> feature</strong>*</p>
<p>A <code>PartitionHub</code> can be used to route elements from a common producer to a dynamic set of consumers. The selection of consumer is done with a function. Each element can be routed to only one consumer. </p>
<p>The rate of the producer will be automatically adapted to the slowest consumer. In this case, the hub is a <code>Sink</code> to which the single producer must be attached first. Consumers can only be attached once the <code>Sink</code> has been materialized (i.e. the producer has been started). One example of using the <code>PartitionHub</code>:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/HubsDocSpec.scala#L111-L130" target="_blank" title="Go to snippet source"></a><code class="language-scala">// A simple producer that publishes a new &quot;message-&quot; every second
val producer = Source.tick(1.second, 1.second, &quot;message&quot;)
  .zipWith(Source(1 to 100))((a, b) ⇒ s&quot;$a-$b&quot;)

// Attach a PartitionHub Sink to the producer. This will materialize to a
// corresponding Source.
// (We need to use toMat and Keep.right since by default the materialized
// value to the left is used)
val runnableGraph: RunnableGraph[Source[String, NotUsed]] =
  producer.toMat(PartitionHub.sink(
    (size, elem) ⇒ math.abs(elem.hashCode % size),
    startAfterNrOfConsumers = 2, bufferSize = 256))(Keep.right)

// By running/materializing the producer, we get back a Source, which
// gives us access to the elements published by the producer.
val fromProducer: Source[String, NotUsed] = runnableGraph.run()

// Print out messages from the producer in two independent consumers
fromProducer.runForeach(msg ⇒ println(&quot;consumer1: &quot; + msg))
fromProducer.runForeach(msg ⇒ println(&quot;consumer2: &quot; + msg))</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/HubDocTest.java#L143-L163" target="_blank" title="Go to snippet source"></a><code class="language-java">// A simple producer that publishes a new &quot;message-n&quot; every second
Source&lt;String, Cancellable&gt; producer =
    Source.tick(Duration.ofSeconds(1), Duration.ofSeconds(1), &quot;message&quot;)
        .zipWith(Source.range(0, 100), (a, b) -&gt; a + &quot;-&quot; + b);

// Attach a PartitionHub Sink to the producer. This will materialize to a
// corresponding Source.
// (We need to use toMat and Keep.right since by default the materialized
// value to the left is used)
RunnableGraph&lt;Source&lt;String, NotUsed&gt;&gt; runnableGraph =
    producer.toMat(
        PartitionHub.of(String.class, (size, elem) -&gt; Math.abs(elem.hashCode() % size), 2, 256),
        Keep.right());

// By running/materializing the producer, we get back a Source, which
// gives us access to the elements published by the producer.
Source&lt;String, NotUsed&gt; fromProducer = runnableGraph.run(materializer);

// Print out messages from the producer in two independent consumers
fromProducer.runForeach(msg -&gt; System.out.println(&quot;consumer1: &quot; + msg), materializer);
fromProducer.runForeach(msg -&gt; System.out.println(&quot;consumer2: &quot; + msg), materializer);</code></pre></dd>
</dl>
<p>The <code>partitioner</code> function takes two parameters; the first is the number of active consumers and the second is the stream element. The function should return the index of the selected consumer for the given element, i.e. <code>int</code> greater than or equal to 0 and less than number of consumers.</p>
<p>The resulting <code>Source</code> can be materialized any number of times, each materialization effectively attaching a new consumer. If there are no consumers attached to this hub then it will not drop any elements but instead backpressure the upstream producer until consumers arrive. This behavior can be tweaked by using an operator, for example <code>.buffer</code> with a drop strategy, or attaching a consumer that drops all messages. If there are no other consumers, this will ensure that the producer is kept drained (dropping all elements) and once a new consumer arrives and messages are routed to the new consumer it will adaptively slow down, ensuring no more messages are dropped.</p>
<p>It is possible to define how many initial consumers that are required before it starts emitting any messages to the attached consumers. While not enough consumers have been attached messages are buffered and when the buffer is full the upstream producer is backpressured. No messages are dropped.</p>
<p>The above example illustrate a stateless partition function. For more advanced stateful routing the <span class="group-java"><code>ofStateful</code></span> <span class="group-scala"><code>statefulSink</code></span> can be used. Here is an example of a stateful round-robin function:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/HubsDocSpec.scala#L136-L166" target="_blank" title="Go to snippet source"></a><code class="language-scala">// A simple producer that publishes a new &quot;message-&quot; every second
val producer = Source.tick(1.second, 1.second, &quot;message&quot;)
  .zipWith(Source(1 to 100))((a, b) ⇒ s&quot;$a-$b&quot;)

// New instance of the partitioner function and its state is created
// for each materialization of the PartitionHub.
def roundRobin(): (PartitionHub.ConsumerInfo, String) ⇒ Long = {
  var i = -1L

  (info, elem) ⇒ {
    i += 1
    info.consumerIdByIdx((i % info.size).toInt)
  }
}

// Attach a PartitionHub Sink to the producer. This will materialize to a
// corresponding Source.
// (We need to use toMat and Keep.right since by default the materialized
// value to the left is used)
val runnableGraph: RunnableGraph[Source[String, NotUsed]] =
  producer.toMat(PartitionHub.statefulSink(
    () ⇒ roundRobin(),
    startAfterNrOfConsumers = 2, bufferSize = 256))(Keep.right)

// By running/materializing the producer, we get back a Source, which
// gives us access to the elements published by the producer.
val fromProducer: Source[String, NotUsed] = runnableGraph.run()

// Print out messages from the producer in two independent consumers
fromProducer.runForeach(msg ⇒ println(&quot;consumer1: &quot; + msg))
fromProducer.runForeach(msg ⇒ println(&quot;consumer2: &quot; + msg))</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/HubDocTest.java#L191-L211" target="_blank" title="Go to snippet source"></a><code class="language-java">// A simple producer that publishes a new &quot;message-n&quot; every second
Source&lt;String, Cancellable&gt; producer =
    Source.tick(Duration.ofSeconds(1), Duration.ofSeconds(1), &quot;message&quot;)
        .zipWith(Source.range(0, 100), (a, b) -&gt; a + &quot;-&quot; + b);

// Attach a PartitionHub Sink to the producer. This will materialize to a
// corresponding Source.
// (We need to use toMat and Keep.right since by default the materialized
// value to the left is used)
RunnableGraph&lt;Source&lt;String, NotUsed&gt;&gt; runnableGraph =
    producer.toMat(
        PartitionHub.ofStateful(String.class, () -&gt; new RoundRobin&lt;String&gt;(), 2, 256),
        Keep.right());

// By running/materializing the producer, we get back a Source, which
// gives us access to the elements published by the producer.
Source&lt;String, NotUsed&gt; fromProducer = runnableGraph.run(materializer);

// Print out messages from the producer in two independent consumers
fromProducer.runForeach(msg -&gt; System.out.println(&quot;consumer1: &quot; + msg), materializer);
fromProducer.runForeach(msg -&gt; System.out.println(&quot;consumer2: &quot; + msg), materializer);</code></pre></dd>
</dl>
<p>Note that it is a factory of a function to to be able to hold stateful variables that are unique for each materialization. <span class="group-java">In this example the <code>partitioner</code> function is implemented as a class to be able to hold the mutable variable. A new instance of <code>RoundRobin</code> is created for each materialization of the hub.</span></p><div class="group-java">
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/HubDocTest.java#L171-L182" target="_blank" title="Go to snippet source"></a><code class="language-java">// Using a class since variable must otherwise be final.
// New instance is created for each materialization of the PartitionHub.
static class RoundRobin&lt;T&gt; implements ToLongBiFunction&lt;ConsumerInfo, T&gt; {

  private long i = -1;

  @Override
  public long applyAsLong(ConsumerInfo info, T elem) {
    i++;
    return info.consumerIdByIdx((int) (i % info.size()));
  }
}</code></pre></div>
<p>The function takes two parameters; the first is information about active consumers, including an array of consumer identifiers and the second is the stream element. The function should return the selected consumer identifier for the given element. The function will never be called when there are no active consumers, i.e. there is always at least one element in the array of identifiers.</p>
<p>Another interesting type of routing is to prefer routing to the fastest consumers. The <code>ConsumerInfo</code> has an accessor <code>queueSize</code> that is approximate number of buffered elements for a consumer. Larger value than other consumers could be an indication of that the consumer is slow. Note that this is a moving target since the elements are consumed concurrently. Here is an example of a hub that routes to the consumer with least buffered elements:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/stream/HubsDocSpec.scala#L172-L185" target="_blank" title="Go to snippet source"></a><code class="language-scala">val producer = Source(0 until 100)

// ConsumerInfo.queueSize is the approximate number of buffered elements for a consumer.
// Note that this is a moving target since the elements are consumed concurrently.
val runnableGraph: RunnableGraph[Source[Int, NotUsed]] =
  producer.toMat(PartitionHub.statefulSink(
    () ⇒ (info, elem) ⇒ info.consumerIds.minBy(id ⇒ info.queueSize(id)),
    startAfterNrOfConsumers = 2, bufferSize = 16))(Keep.right)

val fromProducer: Source[Int, NotUsed] = runnableGraph.run()

fromProducer.runForeach(msg ⇒ println(&quot;consumer1: &quot; + msg))
fromProducer.throttle(10, 100.millis)
  .runForeach(msg ⇒ println(&quot;consumer2: &quot; + msg))</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/stream/HubDocTest.java#L224-L255" target="_blank" title="Go to snippet source"></a><code class="language-java">Source&lt;Integer, NotUsed&gt; producer = Source.range(0, 100);

// ConsumerInfo.queueSize is the approximate number of buffered elements for a consumer.
// Note that this is a moving target since the elements are consumed concurrently.
RunnableGraph&lt;Source&lt;Integer, NotUsed&gt;&gt; runnableGraph =
    producer.toMat(
        PartitionHub.ofStateful(
            Integer.class,
            () -&gt;
                (info, elem) -&gt; {
                  final List&lt;Object&gt; ids = info.getConsumerIds();
                  int minValue = info.queueSize(0);
                  long fastest = info.consumerIdByIdx(0);
                  for (int i = 1; i &lt; ids.size(); i++) {
                    int value = info.queueSize(i);
                    if (value &lt; minValue) {
                      minValue = value;
                      fastest = info.consumerIdByIdx(i);
                    }
                  }
                  return fastest;
                },
            2,
            8),
        Keep.right());

Source&lt;Integer, NotUsed&gt; fromProducer = runnableGraph.run(materializer);

fromProducer.runForeach(msg -&gt; System.out.println(&quot;consumer1: &quot; + msg), materializer);
fromProducer
    .throttle(10, Duration.ofMillis(100))
    .runForeach(msg -&gt; System.out.println(&quot;consumer2: &quot; + msg), materializer);</code></pre></dd>
</dl>
</div>
</article>

<div class="row">
<div class="small-12 large-9 column">
<section class="nav-prev-next row">
<div class="nav-prev small-6 column">
<a href="../stream/stream-rate.html"><i class="icon-prev"></i> <span class="link-prev">Buffers and working with rate</span></a>
</div>
<div class="nav-next small-6 column clearfix">
<a class="float-right" href="../stream/stream-customize.html">Custom stream processing <i class="icon-next"></i></a>
</div>
</section>
</div>
</div>

<div class="source-github row">
Found an error in this documentation? The source code for this page can be found <a href="https://github.com/xmeng1/akka/tree/master/akka-docs-cn/src/main/paradox/stream/stream-dynamic.md">here</a>.
Please feel free to edit and contribute a pull request.
</div>


<footer class="page-footer row clearfix">
<img class="akka-icon float-left show-for-medium" src="../images/akka-icon.svg">
<section class="copyright">
<div>Akka is Open Source and available under the Apache 2 License.</div>
<p class="legal">
&copy; 2011-2019 <a href="https://www.lightbend.com" target="_blank">Lightbend, Inc.</a> | 
<a href="https://www.lightbend.com/legal/licenses" target="_blank">Licenses</a> | 
<a href="https://www.lightbend.com/legal/terms" target="_blank">Terms</a> | 
<a href="https://www.lightbend.com/legal/privacy" target="_blank">Privacy Policy</a> | 
<a href="https://akka.io/cookie/" target="_blank">Cookie Listing</a> | 
<a class="optanon-toggle-display">Cookie Settings</a>
</p>
</section>
</footer>

</section>
</main>

<script type="text/javascript" src="../js/scrollsneak.js"></script>
<script type="text/javascript">jQuery(document).foundation();</script>
<script type="text/javascript" src="../js/groups.js"></script>
<script type="text/javascript" src="../js/page.js"></script>
<script type="text/javascript" src="../js/magellan.js"></script>

<style type="text/css">@import "../lib/prettify/prettify.css";</style>
<script type="text/javascript" src="../lib/prettify/prettify.js"></script>
<script type="text/javascript" src="../lib/prettify/lang-scala.js"></script>
<script type="text/javascript">jQuery(function(){window.prettyPrint && prettyPrint()});</script>

<!-- Algolia docs search -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.js"></script>
<style>.algolia-autocomplete { display: block !important }</style>
<script type="text/javascript">
docsearch({
apiKey: '543bad5ad786495d9ccd445ed34ed082',
indexName: 'akka_io',
inputSelector: '#search',
algoliaOptions: {
hitsPerPage: 5
}
});

docsearch({
apiKey: '543bad5ad786495d9ccd445ed34ed082',
indexName: 'akka_io',
inputSelector: '#overlay-search',
algoliaOptions: {
hitsPerPage: 5
}
});

// set up "/" as global shortcut for focusing on search
jQuery(document).keypress(function (event) {
if (event.keyCode == 47) {
jQuery("#search").focus();
return false; // swallow key event, otherwise the / char would be input into the search box
}
});
</script>

<script type="text/javascript" src="../assets/js/warnOldDocs.js"></script>
<script type="text/javascript" src="../assets/js/scalafiddle.js"></script>


</body>
</html>
