<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
<title>Persistence Query &bull; Akka Documentation 中文</title>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="description" content="akka-docs-cn"/>
<link rel="canonical" href="http://doc.akka.io/docs/akka/current/persistence-query.html"/>
<script type="text/javascript" src="lib/jquery/jquery.min.js"></script>
<script type="text/javascript" src="lib/foundation/dist/js/foundation.min.js"></script>
<link rel="stylesheet" type="text/css" href="lib/normalize.css/normalize.css"/>
<link rel="stylesheet" type="text/css" href="lib/foundation/dist/css/foundation.min.css"/>
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.css" />
<link rel="stylesheet" type="text/css" href="css/icons.css"/>
<link rel="stylesheet" type="text/css" href="css/page.css"/>
<link rel="shortcut icon" href="images/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
<link rel="manifest" href="images/manifest.json">
<meta name="msapplication-TileImage" content="images/mstile-150x150.png">
<meta name="msapplication-TileColor" content="#15a9ce">
<meta name="theme-color" content="#15a9ce">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) start -->
<script src="https://optanon.blob.core.windows.net/consent/159bb13d-6748-4399-806e-ac28db879785.js" type="text/javascript" charset="UTF-8"></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) end -->
<!--Google Analytics-->
<script type="text/plain" class="optanon-category-2">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-21117439-1']);
_gaq.push(['_setDomainName', 'akka.io']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})()
</script>
<script type="text/plain" class="optanon-category-2">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-23127719-1', 'lightbend.com', {'allowLinker': true, 'name': 'tsTracker'});
ga('tsTracker.require', 'linker');
ga('tsTracker.linker:autoLink', ['lightbend.com','playframework.com','scala-lang.org','scaladays.org','spray.io','akka.io','scala-sbt.org','scala-ide.org']);
ga('tsTracker.send', 'pageview');
</script>
<!--Marketo-->
<script type="text/plain" class="optanon-category-3">
(function() {
var didInit = false;
function initMunchkin() {
if(didInit === false) {
didInit = true;
Munchkin.init('558-NCX-702', { 'asyncOnly': true, 'disableClickDelay': true });
}
}
var s = document.createElement('script');
s.type = 'text/javascript';
s.async = true;
s.src = '//munchkin.marketo.net/munchkin.js';
s.onreadystatechange = function() {
if (this.readyState == 'complete' || this.readyState == 'loaded') {
initMunchkin();
}
};
s.onload = initMunchkin;
document.getElementsByTagName('head')[0].appendChild(s);
})();
</script>
</head>

<body id="underlay" data-toggler="nav-open">

<header class="site-header hide-for-large">
<div class="sticky-header clearfix">
<a href="http://akka.io"><img class="logo" src="images/akka-logo-reverse.svg"></a>

<button class="menu-icon float-right" type="button" data-toggle="underlay overlay"></button>
</div>
<div id="overlay" class="overlay-nav" data-toggler="nav-open">
<header class="nav-header">
<div class="nav-header-title">
<h1><a href="index.html">Akka Documentation 中文</a></h1>
</div>
<div class="nav-header-version">
Version 2.5-SNAPSHOT
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-scala">Scala</option><option class="group" value="group-java">Java</option></select>
</div>
<div id="overlay-search-container" class="nav-header-search">
<input id="overlay-search" type="search" class="search" placeholder="Search"/>
</div>
</header>
<nav class="nav-toc">
<ul>
  <li><a href="security/index.html" class="page">Security Announcements</a></li>
  <li><a href="guide/index.html" class="page">Getting Started Guide</a></li>
  <li><a href="general/index.html" class="page">General Concepts</a></li>
  <li><a href="index-actors.html" class="page">Actors</a>
  <ul>
    <li><a href="index-actors.html#dependency" class="header">Dependency</a></li>
    <li><a href="actors.html" class="page">Actors</a></li>
    <li><a href="fault-tolerance.html" class="page">Fault Tolerance</a></li>
    <li><a href="dispatchers.html" class="page">Dispatchers</a></li>
    <li><a href="mailboxes.html" class="page">Mailboxes</a></li>
    <li><a href="routing.html" class="page">Routing</a></li>
    <li><a href="fsm.html" class="page">FSM</a></li>
    <li><a href="persistence.html" class="page">Persistence</a></li>
    <li><a href="persistence-schema-evolution.html" class="page">Persistence - Schema Evolution</a></li>
    <li><a href="persistence-query.html#persistence-query" class="active page">Persistence Query</a>
    <ul>
      <li><a href="persistence-query.html#dependency" class="header">Dependency</a></li>
      <li><a href="persistence-query.html#introduction" class="header">Introduction</a></li>
      <li><a href="persistence-query.html#design-overview" class="header">Design overview</a></li>
      <li><a href="persistence-query.html#read-journals" class="header">Read Journals</a></li>
      <li><a href="persistence-query.html#performance-and-denormalization" class="header">Performance and denormalization</a></li>
      <li><a href="persistence-query.html#query-plugins" class="header">Query plugins</a></li>
      <li><a href="persistence-query.html#scaling-out" class="header">Scaling out</a></li>
    </ul></li>
    <li><a href="persistence-query-leveldb.html" class="page">Persistence Query for LevelDB</a></li>
    <li><a href="persistence-fsm.html" class="page">Persistent FSM</a></li>
    <li><a href="persistence-journals.html" class="page">Persistence - Building a storage backend</a></li>
    <li><a href="testing.html" class="page">Testing Actor Systems</a></li>
  </ul></li>
  <li><a href="typed/index.html" class="page">Akka Typed</a></li>
  <li><a href="index-cluster.html" class="page">Clustering</a></li>
  <li><a href="stream/index.html" class="page">Streams</a></li>
  <li><a href="index-network.html" class="page">Networking</a></li>
  <li><a href="discovery/index.html" class="page">Discovery</a></li>
  <li><a href="index-futures.html" class="page">Futures and Agents</a></li>
  <li><a href="index-utilities.html" class="page">Utilities</a></li>
  <li><a href="common/other-modules.html" class="page">Other Akka modules</a></li>
  <li><a href="howto.html" class="page">HowTo: Common Patterns</a></li>
  <li><a href="project/index.html" class="page">Project Information</a></li>
  <li><a href="additional/index.html" class="page">Additional Information</a></li>
  <li><a href="chinese/index.html" class="page">中文版文档说明</a></li>
</ul>
</nav>
</div>
</header>

<aside class="show-for-large">
<header class="nav-header fixed-sidebar-header">
<div class="nav-header-title">
<h1><a href="index.html">Akka Documentation 中文</a></h1>
</div>
<div class="nav-header-version">
Version 2.5-SNAPSHOT
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-scala">Scala</option><option class="group" value="group-java">Java</option></select>
</div>
<div class="nav-header-search">
<input id="search" type="search" class="search" placeholder="Search"/>
</div>
</header>
<nav class="site-nav fixed-sidebar-contents">
<div class="nav-toc">
<ul>
  <li><a href="security/index.html" class="page">Security Announcements</a></li>
  <li><a href="guide/index.html" class="page">Getting Started Guide</a></li>
  <li><a href="general/index.html" class="page">General Concepts</a></li>
  <li><a href="index-actors.html" class="page">Actors</a>
  <ul>
    <li><a href="index-actors.html#dependency" class="header">Dependency</a></li>
    <li><a href="actors.html" class="page">Actors</a></li>
    <li><a href="fault-tolerance.html" class="page">Fault Tolerance</a></li>
    <li><a href="dispatchers.html" class="page">Dispatchers</a></li>
    <li><a href="mailboxes.html" class="page">Mailboxes</a></li>
    <li><a href="routing.html" class="page">Routing</a></li>
    <li><a href="fsm.html" class="page">FSM</a></li>
    <li><a href="persistence.html" class="page">Persistence</a></li>
    <li><a href="persistence-schema-evolution.html" class="page">Persistence - Schema Evolution</a></li>
    <li><a href="persistence-query.html#persistence-query" class="active page">Persistence Query</a>
    <ul>
      <li><a href="persistence-query.html#dependency" class="header">Dependency</a></li>
      <li><a href="persistence-query.html#introduction" class="header">Introduction</a></li>
      <li><a href="persistence-query.html#design-overview" class="header">Design overview</a></li>
      <li><a href="persistence-query.html#read-journals" class="header">Read Journals</a></li>
      <li><a href="persistence-query.html#performance-and-denormalization" class="header">Performance and denormalization</a></li>
      <li><a href="persistence-query.html#query-plugins" class="header">Query plugins</a></li>
      <li><a href="persistence-query.html#scaling-out" class="header">Scaling out</a></li>
    </ul></li>
    <li><a href="persistence-query-leveldb.html" class="page">Persistence Query for LevelDB</a></li>
    <li><a href="persistence-fsm.html" class="page">Persistent FSM</a></li>
    <li><a href="persistence-journals.html" class="page">Persistence - Building a storage backend</a></li>
    <li><a href="testing.html" class="page">Testing Actor Systems</a></li>
  </ul></li>
  <li><a href="typed/index.html" class="page">Akka Typed</a></li>
  <li><a href="index-cluster.html" class="page">Clustering</a></li>
  <li><a href="stream/index.html" class="page">Streams</a></li>
  <li><a href="index-network.html" class="page">Networking</a></li>
  <li><a href="discovery/index.html" class="page">Discovery</a></li>
  <li><a href="index-futures.html" class="page">Futures and Agents</a></li>
  <li><a href="index-utilities.html" class="page">Utilities</a></li>
  <li><a href="common/other-modules.html" class="page">Other Akka modules</a></li>
  <li><a href="howto.html" class="page">HowTo: Common Patterns</a></li>
  <li><a href="project/index.html" class="page">Project Information</a></li>
  <li><a href="additional/index.html" class="page">Additional Information</a></li>
  <li><a href="chinese/index.html" class="page">中文版文档说明</a></li>
</ul>
</div>
</nav>
<footer class="nav-footer fixed-sidebar-footer">
<a href="http://akka.io"><img class="logo" src="images/akka-logo-reverse.svg"></a>

</footer>
</aside>

<main class="fixed-shift-for-large expanded row">
<section class="site-content small-12 column">

<article class="page-content row">
<div class="small-12 large-9 column" id="docs">
<h1><a href="#persistence-query" name="persistence-query" class="anchor"><span class="anchor-link"></span></a>Persistence Query</h1>
<h2><a href="#dependency" name="dependency" class="anchor"><span class="anchor-link"></span></a>Dependency</h2>
<p>To use Persistence Query, you must add the following dependency in your project:</p><dl class="dependency"><dt>sbt</dt><dd><pre class="prettyprint"><code class="language-scala">libraryDependencies += "com.typesafe.akka" %% "akka-persistence-query" % "2.5-SNAPSHOT"</code></pre></dd><dt>Maven</dt><dd><pre class="prettyprint"><code class="language-xml">&lt;dependency&gt;
  &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt;
  &lt;artifactId&gt;akka-persistence-query_2.12&lt;/artifactId&gt;
  &lt;version&gt;2.5-SNAPSHOT&lt;/version&gt;
&lt;/dependency&gt;</code></pre></dd><dt>Gradle</dt><dd><pre class="prettyprint"><code class="language-gradle">dependencies {
  compile group: 'com.typesafe.akka', name: 'akka-persistence-query_2.12', version: '2.5-SNAPSHOT'
}</code></pre></dd></dl>
<p>This will also add dependency on the <a href="persistence.html">Akka Persistence</a> module.</p>
<h2><a href="#introduction" name="introduction" class="anchor"><span class="anchor-link"></span></a>Introduction</h2>
<p>Akka persistence query complements <a href="persistence.html">Persistence</a> by providing a universal asynchronous stream based query interface that various journal plugins can implement in order to expose their query capabilities.</p>
<p>The most typical use case of persistence query is implementing the so-called query side (also known as &ldquo;read side&rdquo;) in the popular CQRS architecture pattern - in which the writing side of the application (e.g. implemented using akka persistence) is completely separated from the &ldquo;query side&rdquo;. Akka Persistence Query itself is <em>not</em> directly the query side of an application, however it can help to migrate data from the write side to the query side database. In very simple scenarios Persistence Query may be powerful enough to fulfill the query needs of your app, however we highly recommend (in the spirit of CQRS) of splitting up the write/read sides into separate datastores as the need arises.</p>
<h2><a href="#design-overview" name="design-overview" class="anchor"><span class="anchor-link"></span></a>Design overview</h2>
<p>Akka persistence query is purposely designed to be a very loosely specified API. This is in order to keep the provided APIs general enough for each journal implementation to be able to expose its best features, e.g. a SQL journal can use complex SQL queries or if a journal is able to subscribe to a live event stream this should also be possible to expose the same API - a typed stream of events.</p>
<p><strong>Each read journal must explicitly document which types of queries it supports.</strong> Refer to your journal&rsquo;s plugins documentation for details on which queries and semantics it supports.</p>
<p>While Akka Persistence Query does not provide actual implementations of ReadJournals, it defines a number of pre-defined query types for the most common query scenarios, that most journals are likely to implement (however they are not required to).</p>
<h2><a href="#read-journals" name="read-journals" class="anchor"><span class="anchor-link"></span></a>Read Journals</h2>
<p>In order to issue queries one has to first obtain an instance of a <code>ReadJournal</code>. Read journals are implemented as <a href="http://akka.io/community/#plugins-to-akka-persistence-query">Community plugins</a>, each targeting a specific datastore (for example Cassandra or JDBC databases). For example, given a library that provides a <code>akka.persistence.query.my-read-journal</code> obtaining the related journal is as simple as:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L215-L226" target="_blank" title="Go to snippet source"></a><code class="language-scala">// obtain read journal by plugin id
val readJournal =
  PersistenceQuery(system).readJournalFor[MyScaladslReadJournal](
    &quot;akka.persistence.query.my-read-journal&quot;)

// issue query to journal
val source: Source[EventEnvelope, NotUsed] =
  readJournal.eventsByPersistenceId(&quot;user-1337&quot;, 0, Long.MaxValue)

// materialize stream, consuming events
implicit val mat = ActorMaterializer()
source.runForeach { event ⇒ println(&quot;Event: &quot; + event) }</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L212-L224" target="_blank" title="Go to snippet source"></a><code class="language-java">// obtain read journal by plugin id
final MyJavadslReadJournal readJournal =
    PersistenceQuery.get(system)
        .getReadJournalFor(
            MyJavadslReadJournal.class, &quot;akka.persistence.query.my-read-journal&quot;);

// issue query to journal
Source&lt;EventEnvelope, NotUsed&gt; source =
    readJournal.eventsByPersistenceId(&quot;user-1337&quot;, 0, Long.MAX_VALUE);

// materialize stream, consuming events
ActorMaterializer mat = ActorMaterializer.create(system);
source.runForeach(event -&gt; System.out.println(&quot;Event: &quot; + event), mat);</code></pre></dd>
</dl>
<p>Journal implementers are encouraged to put this identifier in a variable known to the user, such that one can access it via <span class="group-scala"><code>readJournalFor[NoopJournal](NoopJournal.identifier)</code></span><span class="group-java"><code>getJournalFor(NoopJournal.class, NoopJournal.identifier)</code></span>, however this is not enforced.</p>
<p>Read journal implementations are available as <a href="http://akka.io/community/#plugins-to-akka-persistence-query">Community plugins</a>.</p>
<h3><a href="#predefined-queries" name="predefined-queries" class="anchor"><span class="anchor-link"></span></a>Predefined queries</h3>
<p>Akka persistence query comes with a number of query interfaces built in and suggests Journal implementors to implement them according to the semantics described below. It is important to notice that while these query types are very common a journal is not obliged to implement all of them - for example because in a given journal such query would be significantly inefficient.</p><div class="callout note "><div class="callout-title">Note</div>
<p>Refer to the documentation of the <code>ReadJournal</code> plugin you are using for a specific list of supported query types. For example, Journal plugins should document their stream completion strategies.</p></div>
<p>The predefined queries are:</p>
<h4><a href="#persistenceidsquery-and-currentpersistenceidsquery" name="persistenceidsquery-and-currentpersistenceidsquery" class="anchor"><span class="anchor-link"></span></a>PersistenceIdsQuery and CurrentPersistenceIdsQuery</h4>
<p><code>persistenceIds</code> which is designed to allow users to subscribe to a stream of all persistent ids in the system. By default this stream should be assumed to be a &ldquo;live&rdquo; stream, which means that the journal should keep emitting new persistence ids as they come into the system:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L230" target="_blank" title="Go to snippet source"></a><code class="language-scala">readJournal.persistenceIds()</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L235" target="_blank" title="Go to snippet source"></a><code class="language-java">readJournal.persistenceIds();</code></pre></dd>
</dl>
<p>If your usage does not require a live stream, you can use the <code>currentPersistenceIds</code> query:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L234" target="_blank" title="Go to snippet source"></a><code class="language-scala">readJournal.currentPersistenceIds()</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L248" target="_blank" title="Go to snippet source"></a><code class="language-java">readJournal.currentPersistenceIds();</code></pre></dd>
</dl>
<h4><a href="#eventsbypersistenceidquery-and-currenteventsbypersistenceidquery" name="eventsbypersistenceidquery-and-currenteventsbypersistenceidquery" class="anchor"><span class="anchor-link"></span></a>EventsByPersistenceIdQuery and CurrentEventsByPersistenceIdQuery</h4>
<p><code>eventsByPersistenceId</code> is a query equivalent to replaying a <a href="persistence.html#event-sourcing">PersistentActor</a>, however, since it is a stream it is possible to keep it alive and watch for additional incoming events persisted by the persistent actor identified by the given <code>persistenceId</code>.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L255-L256" target="_blank" title="Go to snippet source"></a><code class="language-scala">readJournal.eventsByPersistenceId(&quot;user-us-1337&quot;, fromSequenceNr = 0L, toSequenceNr = Long.MaxValue)
</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L261" target="_blank" title="Go to snippet source"></a><code class="language-java">readJournal.eventsByPersistenceId(&quot;user-us-1337&quot;, 0L, Long.MAX_VALUE);</code></pre></dd>
</dl>
<p>Most journals will have to revert to polling in order to achieve this, which can typically be configured with a <code>refresh-interval</code> configuration property.</p>
<p>If your usage does not require a live stream, you can use the <code>currentEventsByPersistenceId</code> query.</p>
<h4><a href="#eventsbytag-and-currenteventsbytag" name="eventsbytag-and-currenteventsbytag" class="anchor"><span class="anchor-link"></span></a>EventsByTag and CurrentEventsByTag</h4>
<p><code>eventsByTag</code> allows querying events regardless of which <code>persistenceId</code> they are associated with. This query is hard to implement in some journals or may need some additional preparation of the used data store to be executed efficiently. The goal of this query is to allow querying for all events which are &ldquo;tagged&rdquo; with a specific tag. That includes the use case to query all domain events of an Aggregate Root type. Please refer to your read journal plugin&rsquo;s documentation to find out if and how it is supported.</p>
<p>Some journals may support tagging of events via an <a href="persistence.html#event-adapters">Event Adapters</a> that wraps the events in a <code>akka.persistence.journal.Tagged</code> with the given <code>tags</code>. The journal may support other ways of doing tagging - again, how exactly this is implemented depends on the used journal. Here is an example of such a tagging event adapter:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/LeveldbPersistenceQueryDocSpec.scala#L21-L37" target="_blank" title="Go to snippet source"></a><code class="language-scala">import akka.persistence.journal.WriteEventAdapter
import akka.persistence.journal.Tagged

class MyTaggingEventAdapter extends WriteEventAdapter {
  val colors = Set(&quot;green&quot;, &quot;black&quot;, &quot;blue&quot;)
  override def toJournal(event: Any): Any = event match {
    case s: String ⇒
      var tags = colors.foldLeft(Set.empty[String]) { (acc, c) ⇒
        if (s.contains(c)) acc + c else acc
      }
      if (tags.isEmpty) event
      else Tagged(event, tags)
    case _ ⇒ event
  }

  override def manifest(event: Any): String = &quot;&quot;
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/query/LeveldbPersistenceQueryDocTest.java#L68-L89" target="_blank" title="Go to snippet source"></a><code class="language-java">static class MyTaggingEventAdapter implements WriteEventAdapter {

  @Override
  public Object toJournal(Object event) {
    if (event instanceof String) {
      String s = (String) event;
      Set&lt;String&gt; tags = new HashSet&lt;String&gt;();
      if (s.contains(&quot;green&quot;)) tags.add(&quot;green&quot;);
      if (s.contains(&quot;black&quot;)) tags.add(&quot;black&quot;);
      if (s.contains(&quot;blue&quot;)) tags.add(&quot;blue&quot;);
      if (tags.isEmpty()) return event;
      else return new Tagged(event, tags);
    } else {
      return event;
    }
  }

  @Override
  public String manifest(Object event) {
    return &quot;&quot;;
  }
}</code></pre></dd>
</dl><div class="callout note "><div class="callout-title">Note</div>
<p>A very important thing to keep in mind when using queries spanning multiple persistenceIds, such as <code>EventsByTag</code> is that the order of events at which the events appear in the stream rarely is guaranteed (or stable between materializations).</p>
<p>Journals <em>may</em> choose to opt for strict ordering of the events, and should then document explicitly what kind of ordering guarantee they provide - for example &ldquo;<em>ordered by timestamp ascending, independently of persistenceId</em>&rdquo; is easy to achieve on relational databases, yet may be hard to implement efficiently on plain key-value datastores.</p></div>
<p>In the example below we query all events which have been tagged (we assume this was performed by the write-side using an <a href="persistence.html#event-adapters">EventAdapter</a>, or that the journal is smart enough that it can figure out what we mean by this tag - for example if the journal stored the events as json it may try to find those with the field <code>tag</code> set to this value etc.).</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L238-L251" target="_blank" title="Go to snippet source"></a><code class="language-scala">// assuming journal is able to work with numeric offsets we can:

val blueThings: Source[EventEnvelope, NotUsed] =
  readJournal.eventsByTag(&quot;blue&quot;, Offset.noOffset)

// find top 10 blue things:
val top10BlueThings: Future[Vector[Any]] =
  blueThings
    .map(_.event)
    .take(10) // cancels the query stream after pulling 10 elements
    .runFold(Vector.empty[Any])(_ :+ _)

// start another query, from the known offset
val furtherBlueThings = readJournal.eventsByTag(&quot;blue&quot;, offset = Sequence(10))</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L275-L293" target="_blank" title="Go to snippet source"></a><code class="language-java">// assuming journal is able to work with numeric offsets we can:
final Source&lt;EventEnvelope, NotUsed&gt; blueThings =
    readJournal.eventsByTag(&quot;blue&quot;, new Sequence(0L));

// find top 10 blue things:
final CompletionStage&lt;List&lt;Object&gt;&gt; top10BlueThings =
    blueThings
        .map(EventEnvelope::event)
        .take(10) // cancels the query stream after pulling 10 elements
        .runFold(
            new ArrayList&lt;&gt;(10),
            (acc, e) -&gt; {
              acc.add(e);
              return acc;
            },
            mat);

// start another query, from the known offset
Source&lt;EventEnvelope, NotUsed&gt; blue = readJournal.eventsByTag(&quot;blue&quot;, new Sequence(10));</code></pre></dd>
</dl>
<p>As you can see, we can use all the usual stream operators available from <a href="stream/index.html">Streams</a> on the resulting query stream, including for example taking the first 10 and cancelling the stream. It is worth pointing out that the built-in <code>EventsByTag</code> query has an optionally supported offset parameter (of type <code>Long</code>) which the journals can use to implement resumable-streams. For example a journal may be able to use a WHERE clause to begin the read starting from a specific row, or in a datastore that is able to order events by insertion time it could treat the Long as a timestamp and select only older events.</p>
<p>If your usage does not require a live stream, you can use the <code>currentEventsByTag</code> query.</p>
<h3><a href="#materialized-values-of-queries" name="materialized-values-of-queries" class="anchor"><span class="anchor-link"></span></a>Materialized values of queries</h3>
<p>Journals are able to provide additional information related to a query by exposing <a href="stream/stream-quickstart.html#materialized-values-quick">Materialized values</a>, which are a feature of <a href="stream/index.html">Streams</a> that allows to expose additional values at stream materialization time.</p>
<p>More advanced query journals may use this technique to expose information about the character of the materialized stream, for example if it&rsquo;s finite or infinite, strictly ordered or not ordered at all. The materialized value type is defined as the second type parameter of the returned <code>Source</code>, which allows journals to provide users with their specialised query object, as demonstrated in the sample below:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L30-L33" target="_blank" title="Go to snippet source"></a><code class="language-scala">final case class RichEvent(tags: Set[String], payload: Any)

// a plugin can provide:
case class QueryMetadata(deterministicOrder: Boolean, infinite: Boolean)</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L40-L62" target="_blank" title="Go to snippet source"></a><code class="language-java">static class RichEvent {
  public final Set&lt;String&gt; tags;
  public final Object payload;

  public RichEvent(Set&lt;String&gt; tags, Object payload) {
    this.tags = tags;
    this.payload = payload;
  }
}
// a plugin can provide:
static final class QueryMetadata {
  public final boolean deterministicOrder;
  public final boolean infinite;

  public QueryMetadata(boolean deterministicOrder, boolean infinite) {
    this.deterministicOrder = deterministicOrder;
    this.infinite = infinite;
  }
}</code></pre></dd>
</dl>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L99" target="_blank" title="Go to snippet source"></a><code class="language-scala">def byTagsWithMeta(tags: Set[String]): Source[RichEvent, QueryMetadata] = {</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L151" target="_blank" title="Go to snippet source"></a><code class="language-java">public Source&lt;RichEvent, QueryMetadata&gt; byTagsWithMeta(Set&lt;String&gt; tags) {</code></pre></dd>
</dl>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L260-L271" target="_blank" title="Go to snippet source"></a><code class="language-scala">val query: Source[RichEvent, QueryMetadata] =
  readJournal.byTagsWithMeta(Set(&quot;red&quot;, &quot;blue&quot;))

query
  .mapMaterializedValue { meta ⇒
    println(s&quot;The query is: &quot; +
      s&quot;ordered deterministically: ${meta.deterministicOrder}, &quot; +
      s&quot;infinite: ${meta.infinite}&quot;)
  }
  .map { event ⇒ println(s&quot;Event payload: ${event.payload}&quot;) }
  .runWith(Sink.ignore)
</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L307-L333" target="_blank" title="Go to snippet source"></a><code class="language-java"><br/>Set&lt;String&gt; tags = new HashSet&lt;String&gt;();
tags.add(&quot;red&quot;);
tags.add(&quot;blue&quot;);
final Source&lt;RichEvent, QueryMetadata&gt; events =
    readJournal
        .byTagsWithMeta(tags)
        .mapMaterializedValue(
            meta -&gt; {
              System.out.println(
                  &quot;The query is: &quot;
                      + &quot;ordered deterministically: &quot;
                      + meta.deterministicOrder
                      + &quot; &quot;
                      + &quot;infinite: &quot;
                      + meta.infinite);
              return meta;
            });

events
    .map(
        event -&gt; {
          System.out.println(&quot;Event payload: &quot; + event.payload);
          return event.payload;
        })
    .runWith(Sink.ignore(), mat);
</code></pre></dd>
</dl>
<h2><a href="#performance-and-denormalization" name="performance-and-denormalization" class="anchor"><span class="anchor-link"></span></a>Performance and denormalization</h2>
<p>When building systems using <a href="persistence.html#event-sourcing">Event sourcing</a> and CQRS (<a href="https://msdn.microsoft.com/en-us/library/jj554200.aspx">Command &amp; Query Responsibility Segregation</a>) techniques it is tremendously important to realise that the write-side has completely different needs from the read-side, and separating those concerns into datastores that are optimised for either side makes it possible to offer the best experience for the write and read sides independently.</p>
<p>For example, in a bidding system it is important to &ldquo;take the write&rdquo; and respond to the bidder that we have accepted the bid as soon as possible, which means that write-throughput is of highest importance for the write-side – often this means that data stores which are able to scale to accommodate these requirements have a less expressive query side.</p>
<p>On the other hand the same application may have some complex statistics view or we may have analysts working with the data to figure out best bidding strategies and trends – this often requires some kind of expressive query capabilities like for example SQL or writing Spark jobs to analyse the data. Therefore the data stored in the write-side needs to be projected into the other read-optimised datastore.</p><div class="callout note "><div class="callout-title">Note</div>
<p>When referring to <strong>Materialized Views</strong> in Akka Persistence think of it as &ldquo;some persistent storage of the result of a Query&rdquo;. In other words, it means that the view is created once, in order to be afterwards queried multiple times, as in this format it may be more efficient or interesting to query it (instead of the source events directly).</p></div>
<h3><a href="#materialize-view-to-reactive-streams-compatible-datastore" name="materialize-view-to-reactive-streams-compatible-datastore" class="anchor"><span class="anchor-link"></span></a>Materialize view to Reactive Streams compatible datastore</h3>
<p>If the read datastore exposes a <a href="http://reactive-streams.org">Reactive Streams</a> interface then implementing a simple projection is as simple as, using the read-journal and feeding it into the databases driver interface, for example like so:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L158-L172" target="_blank" title="Go to snippet source"></a><code class="language-scala">implicit val system = ActorSystem()
implicit val mat = ActorMaterializer()

val readJournal =
  PersistenceQuery(system).readJournalFor[MyScaladslReadJournal](JournalId)
val dbBatchWriter: Subscriber[immutable.Seq[Any]] =
  ReactiveStreamsCompatibleDBDriver.batchWriter

// Using an example (Reactive Streams) Database driver
readJournal
  .eventsByPersistenceId(&quot;user-1337&quot;, fromSequenceNr = 0L, toSequenceNr = Long.MaxValue)
  .map(envelope ⇒ envelope.event)
  .map(convertToReadSideTypes) // convert to datatype
  .grouped(20) // batch inserts into groups of 20
  .runWith(Sink.fromSubscriber(dbBatchWriter)) // write batches to read-side database</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L353-L361" target="_blank" title="Go to snippet source"></a><code class="language-java">final ReactiveStreamsCompatibleDBDriver driver = new ReactiveStreamsCompatibleDBDriver();
final Subscriber&lt;List&lt;Object&gt;&gt; dbBatchWriter = driver.batchWriter();

// Using an example (Reactive Streams) Database driver
readJournal
    .eventsByPersistenceId(&quot;user-1337&quot;, 0L, Long.MAX_VALUE)
    .map(envelope -&gt; envelope.event())
    .grouped(20) // batch inserts into groups of 20
    .runWith(Sink.fromSubscriber(dbBatchWriter), mat); // write batches to read-side database</code></pre></dd>
</dl>
<h3><a href="#materialize-view-using-mapasync" name="materialize-view-using-mapasync" class="anchor"><span class="anchor-link"></span></a>Materialize view using mapAsync</h3>
<p>If the target database does not provide a reactive streams <code>Subscriber</code> that can perform writes, you may have to implement the write logic using plain functions or Actors instead.</p>
<p>In case your write logic is state-less and you need to convert the events from one data type to another before writing into the alternative datastore, then the projection will look like this:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L312-L314" target="_blank" title="Go to snippet source"></a><code class="language-scala">trait ExampleStore {
  def save(event: Any): Future[Unit]
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L366-L373" target="_blank" title="Go to snippet source"></a><code class="language-java">class ExampleStore {
  CompletionStage&lt;Void&gt; save(Object any) {
    // ...
  }
}</code></pre></dd>
</dl>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L318-L323" target="_blank" title="Go to snippet source"></a><code class="language-scala">val store: ExampleStore = ???

readJournal
  .eventsByTag(&quot;bid&quot;, NoOffset)
  .mapAsync(1) { e ⇒ store.save(e) }
  .runWith(Sink.ignore)</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L386-L391" target="_blank" title="Go to snippet source"></a><code class="language-java">final ExampleStore store = new ExampleStore();

readJournal
    .eventsByTag(&quot;bid&quot;, new Sequence(0L))
    .mapAsync(1, store::save)
    .runWith(Sink.ignore(), mat);</code></pre></dd>
</dl>
<h3><a href="#resumable-projections" name="resumable-projections" class="anchor"><span class="anchor-link"></span></a>Resumable projections</h3>
<p>Sometimes you may need to implement &ldquo;resumable&rdquo; projections, that will not start from the beginning of time each time when run. In this case you will need to store the sequence number (or <code>offset</code>) of the processed event and use it the next time this projection is started. This pattern is not built-in, however is rather simple to implement yourself.</p>
<p>The example below additionally highlights how you would use Actors to implement the write side, in case you need to do some complex logic that would be best handled inside an Actor before persisting the event into the other datastore:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L287-L302" target="_blank" title="Go to snippet source"></a><code class="language-scala">import akka.pattern.ask
import system.dispatcher
implicit val timeout = Timeout(3.seconds)

val bidProjection = new MyResumableProjection(&quot;bid&quot;)

val writerProps = Props(classOf[TheOneWhoWritesToQueryJournal], &quot;bid&quot;)
val writer = system.actorOf(writerProps, &quot;bid-projection-writer&quot;)

bidProjection.latestOffset.foreach { startFromOffset ⇒
  readJournal
    .eventsByTag(&quot;bid&quot;, Sequence(startFromOffset))
    .mapAsync(8) { envelope ⇒ (writer ? envelope.event).map(_ ⇒ envelope.offset) }
    .mapAsync(1) { offset ⇒ bidProjection.saveProgress(offset) }
    .runWith(Sink.ignore)
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L429-L450" target="_blank" title="Go to snippet source"></a><code class="language-java">  final Duration timeout = Duration.ofSeconds(3);

  final MyResumableProjection bidProjection = new MyResumableProjection(&quot;bid&quot;);

  final Props writerProps = Props.create(TheOneWhoWritesToQueryJournal.class, &quot;bid&quot;);
  final ActorRef writer = system.actorOf(writerProps, &quot;bid-projection-writer&quot;);

  long startFromOffset =
      bidProjection.latestOffset().toCompletableFuture().get(3, TimeUnit.SECONDS);

  readJournal
      .eventsByTag(&quot;bid&quot;, new Sequence(startFromOffset))
      .mapAsync(
          8,
          envelope -&gt; {
            final CompletionStage&lt;Object&gt; f = ask(writer, envelope.event(), timeout);
            return f.thenApplyAsync(in -&gt; envelope.offset(), system.dispatcher());
          })
      .mapAsync(1, offset -&gt; bidProjection.saveProgress(offset))
      .runWith(Sink.ignore(), mat);
}
</code></pre></dd>
</dl>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L177-L193" target="_blank" title="Go to snippet source"></a><code class="language-scala">class TheOneWhoWritesToQueryJournal(id: String) extends Actor {
  val store = new DummyStore()

  var state: ComplexState = ComplexState()

  def receive = {
    case m ⇒
      state = updateState(state, m)
      if (state.readyToSave) store.save(Record(state))
  }

  def updateState(state: ComplexState, msg: Any): ComplexState = {
    // some complicated aggregation logic here ...
    state
  }
}
</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L467-L493" target="_blank" title="Go to snippet source"></a><code class="language-java">final class TheOneWhoWritesToQueryJournal extends AbstractActor {
  private final ExampleStore store;

  private ComplexState state = new ComplexState();

  public TheOneWhoWritesToQueryJournal() {
    store = new ExampleStore();
  }

  @Override
  public Receive createReceive() {
    return receiveBuilder()
        .matchAny(
            message -&gt; {
              state = updateState(state, message);

              // example saving logic that requires state to become ready:
              if (state.readyToSave()) store.save(Record.of(state));
            })
        .build();
  }

  ComplexState updateState(ComplexState state, Object msg) {
    // some complicated aggregation logic here ...
    return state;
  }
}</code></pre></dd>
</dl>
<a id="read-journal-plugin-api"></a>
<h2><a href="#query-plugins" name="query-plugins" class="anchor"><span class="anchor-link"></span></a>Query plugins</h2>
<p>Query plugins are various (mostly community driven) <code>ReadJournal</code> implementations for all kinds of available datastores. The complete list of available plugins is maintained on the Akka Persistence Query <a href="http://akka.io/community/#plugins-to-akka-persistence-query">Community Plugins</a> page.</p>
<p>The plugin for LevelDB is described in <a href="persistence-query-leveldb.html">Persistence Query for LevelDB</a>.</p>
<p>This section aims to provide tips and guide plugin developers through implementing a custom query plugin. Most users will not need to implement journals themselves, except if targeting a not yet supported datastore.</p><div class="callout note "><div class="callout-title">Note</div>
<p>Since different data stores provide different query capabilities journal plugins <strong>must extensively document</strong> their exposed semantics as well as handled query scenarios.</p></div>
<h3><a href="#readjournal-plugin-api" name="readjournal-plugin-api" class="anchor"><span class="anchor-link"></span></a>ReadJournal plugin API</h3>
<p>A read journal plugin must implement <code>akka.persistence.query.ReadJournalProvider</code> which creates instances of <code>akka.persistence.query.scaladsl.ReadJournal</code> and <code>akka.persistence.query.javaadsl.ReadJournal</code>. The plugin must implement both the <code>scaladsl</code> and the <code>javadsl</code> <span class="group-scala">traits</span><span class="group-java">interfaces</span> because the <code>akka.stream.scaladsl.Source</code> and <code>akka.stream.javadsl.Source</code> are different types and even though those types can be converted to each other it is most convenient for the end user to get access to the Java or Scala <code>Source</code> directly. As illustrated below one of the implementations can delegate to the other. </p>
<p>Below is a simple journal implementation:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/PersistenceQueryDocSpec.scala#L37-L138" target="_blank" title="Go to snippet source"></a><code class="language-scala">class MyReadJournalProvider(system: ExtendedActorSystem, config: Config)
  extends ReadJournalProvider {

  override val scaladslReadJournal: MyScaladslReadJournal =
    new MyScaladslReadJournal(system, config)

  override val javadslReadJournal: MyJavadslReadJournal =
    new MyJavadslReadJournal(scaladslReadJournal)
}

class MyScaladslReadJournal(system: ExtendedActorSystem, config: Config)
  extends akka.persistence.query.scaladsl.ReadJournal
  with akka.persistence.query.scaladsl.EventsByTagQuery
  with akka.persistence.query.scaladsl.EventsByPersistenceIdQuery
  with akka.persistence.query.scaladsl.PersistenceIdsQuery
  with akka.persistence.query.scaladsl.CurrentPersistenceIdsQuery {

  private val refreshInterval: FiniteDuration =
    config.getDuration(&quot;refresh-interval&quot;, MILLISECONDS).millis

  /**
   * You can use `NoOffset` to retrieve all events with a given tag or retrieve a subset of all
   * events by specifying a `Sequence` `offset`. The `offset` corresponds to an ordered sequence number for
   * the specific tag. Note that the corresponding offset of each event is provided in the
   * [[akka.persistence.query.EventEnvelope]], which makes it possible to resume the
   * stream at a later point from a given offset.
   *
   * The `offset` is exclusive, i.e. the event with the exact same sequence number will not be included
   * in the returned stream. This means that you can use the offset that is returned in `EventEnvelope`
   * as the `offset` parameter in a subsequent query.
   */
  override def eventsByTag(
    tag: String, offset: Offset): Source[EventEnvelope, NotUsed] = offset match {
    case Sequence(offsetValue) ⇒
      val props = MyEventsByTagPublisher.props(tag, offsetValue, refreshInterval)
      Source.actorPublisher[EventEnvelope](props)
        .mapMaterializedValue(_ ⇒ NotUsed)
    case NoOffset ⇒ eventsByTag(tag, Sequence(0L)) //recursive
    case _ ⇒
      throw new IllegalArgumentException(&quot;LevelDB does not support &quot; + offset.getClass.getName + &quot; offsets&quot;)
  }

  override def eventsByPersistenceId(
    persistenceId: String, fromSequenceNr: Long,
    toSequenceNr: Long): Source[EventEnvelope, NotUsed] = {
    // implement in a similar way as eventsByTag
    ???
  }

  override def persistenceIds(): Source[String, NotUsed] = {
    // implement in a similar way as eventsByTag
    ???
  }

  override def currentPersistenceIds(): Source[String, NotUsed] = {
    // implement in a similar way as eventsByTag
    ???
  }

  // possibility to add more plugin specific queries

  def byTagsWithMeta(tags: Set[String]): Source[RichEvent, QueryMetadata] = {
    // implement in a similar way as eventsByTag
    ???
  }

}

class MyJavadslReadJournal(scaladslReadJournal: MyScaladslReadJournal)
  extends akka.persistence.query.javadsl.ReadJournal
  with akka.persistence.query.javadsl.EventsByTagQuery
  with akka.persistence.query.javadsl.EventsByPersistenceIdQuery
  with akka.persistence.query.javadsl.PersistenceIdsQuery
  with akka.persistence.query.javadsl.CurrentPersistenceIdsQuery {

  override def eventsByTag(
    tag: String, offset: Offset = Sequence(0L)): javadsl.Source[EventEnvelope, NotUsed] =
    scaladslReadJournal.eventsByTag(tag, offset).asJava

  override def eventsByPersistenceId(
    persistenceId: String, fromSequenceNr: Long = 0L,
    toSequenceNr: Long = Long.MaxValue): javadsl.Source[EventEnvelope, NotUsed] =
    scaladslReadJournal.eventsByPersistenceId(
      persistenceId, fromSequenceNr, toSequenceNr).asJava

  override def persistenceIds(): javadsl.Source[String, NotUsed] =
    scaladslReadJournal.persistenceIds().asJava

  override def currentPersistenceIds(): javadsl.Source[String, NotUsed] =
    scaladslReadJournal.currentPersistenceIds().asJava

  // possibility to add more plugin specific queries

  def byTagsWithMeta(
    tags: java.util.Set[String]): javadsl.Source[RichEvent, QueryMetadata] = {
    import scala.collection.JavaConverters._
    scaladslReadJournal.byTagsWithMeta(tags.asScala.toSet).asJava
  }
}
</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/PersistenceQueryDocTest.java#L67-L205" target="_blank" title="Go to snippet source"></a><code class="language-java">static class MyReadJournalProvider implements ReadJournalProvider {
  private final MyJavadslReadJournal javadslReadJournal;

  public MyReadJournalProvider(ExtendedActorSystem system, Config config) {
    this.javadslReadJournal = new MyJavadslReadJournal(system, config);
  }

  @Override
  public MyScaladslReadJournal scaladslReadJournal() {
    return new MyScaladslReadJournal(javadslReadJournal);
  }

  @Override
  public MyJavadslReadJournal javadslReadJournal() {
    return this.javadslReadJournal;
  }
}
static class MyJavadslReadJournal
    implements akka.persistence.query.javadsl.ReadJournal,
        akka.persistence.query.javadsl.EventsByTagQuery,
        akka.persistence.query.javadsl.EventsByPersistenceIdQuery,
        akka.persistence.query.javadsl.PersistenceIdsQuery,
        akka.persistence.query.javadsl.CurrentPersistenceIdsQuery {

  private final FiniteDuration refreshInterval;

  public MyJavadslReadJournal(ExtendedActorSystem system, Config config) {
    refreshInterval =
        FiniteDuration.create(
            config.getDuration(&quot;refresh-interval&quot;, TimeUnit.MILLISECONDS), TimeUnit.MILLISECONDS);
  }

  /**
   * You can use `NoOffset` to retrieve all events with a given tag or retrieve a subset of all
   * events by specifying a `Sequence` `offset`. The `offset` corresponds to an ordered sequence
   * number for the specific tag. Note that the corresponding offset of each event is provided in
   * the [[akka.persistence.query.EventEnvelope]], which makes it possible to resume the stream at
   * a later point from a given offset.
   *
   * &lt;p&gt;The `offset` is exclusive, i.e. the event with the exact same sequence number will not be
   * included in the returned stream. This means that you can use the offset that is returned in
   * `EventEnvelope` as the `offset` parameter in a subsequent query.
   */
  @Override
  public Source&lt;EventEnvelope, NotUsed&gt; eventsByTag(String tag, Offset offset) {
    if (offset instanceof Sequence) {
      Sequence sequenceOffset = (Sequence) offset;
      final Props props =
          MyEventsByTagPublisher.props(tag, sequenceOffset.value(), refreshInterval);
      return Source.&lt;EventEnvelope&gt;actorPublisher(props)
          .mapMaterializedValue(m -&gt; NotUsed.getInstance());
    } else if (offset == NoOffset.getInstance())
      return eventsByTag(tag, Offset.sequence(0L)); // recursive
    else
      throw new IllegalArgumentException(
          &quot;MyJavadslReadJournal does not support &quot; + offset.getClass().getName() + &quot; offsets&quot;);
  }

  @Override
  public Source&lt;EventEnvelope, NotUsed&gt; eventsByPersistenceId(
      String persistenceId, long fromSequenceNr, long toSequenceNr) {
    // implement in a similar way as eventsByTag
    throw new UnsupportedOperationException(&quot;Not implemented yet&quot;);
  }

  @Override
  public Source&lt;String, NotUsed&gt; persistenceIds() {
    // implement in a similar way as eventsByTag
    throw new UnsupportedOperationException(&quot;Not implemented yet&quot;);
  }

  @Override
  public Source&lt;String, NotUsed&gt; currentPersistenceIds() {
    // implement in a similar way as eventsByTag
    throw new UnsupportedOperationException(&quot;Not implemented yet&quot;);
  }

  // possibility to add more plugin specific queries

  public Source&lt;RichEvent, QueryMetadata&gt; byTagsWithMeta(Set&lt;String&gt; tags) {
    // implement in a similar way as eventsByTag
    throw new UnsupportedOperationException(&quot;Not implemented yet&quot;);
  }
}
static class MyScaladslReadJournal
    implements akka.persistence.query.scaladsl.ReadJournal,
        akka.persistence.query.scaladsl.EventsByTagQuery,
        akka.persistence.query.scaladsl.EventsByPersistenceIdQuery,
        akka.persistence.query.scaladsl.PersistenceIdsQuery,
        akka.persistence.query.scaladsl.CurrentPersistenceIdsQuery {

  private final MyJavadslReadJournal javadslReadJournal;

  public MyScaladslReadJournal(MyJavadslReadJournal javadslReadJournal) {
    this.javadslReadJournal = javadslReadJournal;
  }

  @Override
  public akka.stream.scaladsl.Source&lt;EventEnvelope, NotUsed&gt; eventsByTag(
      String tag, akka.persistence.query.Offset offset) {
    return javadslReadJournal.eventsByTag(tag, offset).asScala();
  }

  @Override
  public akka.stream.scaladsl.Source&lt;EventEnvelope, NotUsed&gt; eventsByPersistenceId(
      String persistenceId, long fromSequenceNr, long toSequenceNr) {
    return javadslReadJournal
        .eventsByPersistenceId(persistenceId, fromSequenceNr, toSequenceNr)
        .asScala();
  }

  @Override
  public akka.stream.scaladsl.Source&lt;String, NotUsed&gt; persistenceIds() {
    return javadslReadJournal.persistenceIds().asScala();
  }

  @Override
  public akka.stream.scaladsl.Source&lt;String, NotUsed&gt; currentPersistenceIds() {
    return javadslReadJournal.currentPersistenceIds().asScala();
  }

  // possibility to add more plugin specific queries

  public akka.stream.scaladsl.Source&lt;RichEvent, QueryMetadata&gt; byTagsWithMeta(
      scala.collection.Set&lt;String&gt; tags) {
    Set&lt;String&gt; jTags = scala.collection.JavaConverters.setAsJavaSetConverter(tags).asJava();
    return javadslReadJournal.byTagsWithMeta(jTags).asScala();
  }
}</code></pre></dd>
</dl>
<p>And the <code>eventsByTag</code> could be backed by such an Actor for example:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/scala/docs/persistence/query/MyEventsByTagPublisher.scala#L22-L103" target="_blank" title="Go to snippet source"></a><code class="language-scala">class MyEventsByTagPublisher(tag: String, offset: Long, refreshInterval: FiniteDuration)
  extends ActorPublisher[EventEnvelope] {

  private case object Continue

  private val connection: java.sql.Connection = ???

  private val Limit = 1000
  private var currentOffset = offset
  var buf = Vector.empty[EventEnvelope]

  import context.dispatcher
  val continueTask = context.system.scheduler.schedule(
    refreshInterval, refreshInterval, self, Continue)

  override def postStop(): Unit = {
    continueTask.cancel()
  }

  def receive = {
    case _: Request | Continue ⇒
      query()
      deliverBuf()

    case Cancel ⇒
      context.stop(self)
  }

  object Select {
    private def statement() = connection.prepareStatement(
      &quot;&quot;&quot;
        SELECT id, persistent_repr FROM journal
        WHERE tag = ? AND id &gt; ?
        ORDER BY id LIMIT ?
      &quot;&quot;&quot;)

    def run(tag: String, from: Long, limit: Int): Vector[(Long, Array[Byte])] = {
      val s = statement()
      try {
        s.setString(1, tag)
        s.setLong(2, from)
        s.setLong(3, limit)
        val rs = s.executeQuery()

        val b = Vector.newBuilder[(Long, Array[Byte])]
        while (rs.next())
          b += (rs.getLong(1) -&gt; rs.getBytes(2))
        b.result()
      } finally s.close()
    }
  }

  def query(): Unit =
    if (buf.isEmpty) {
      try {
        val result = Select.run(tag, currentOffset, Limit)
        currentOffset = if (result.nonEmpty) result.last._1 else currentOffset
        val serialization = SerializationExtension(context.system)

        buf = result.map {
          case (id, bytes) ⇒
            val p = serialization.deserialize(bytes, classOf[PersistentRepr]).get
            EventEnvelope(offset = Sequence(id), p.persistenceId, p.sequenceNr, p.payload)
        }
      } catch {
        case e: Exception ⇒
          onErrorThenStop(e)
      }
    }

  final def deliverBuf(): Unit =
    if (totalDemand &gt; 0 &amp;&amp; buf.nonEmpty) {
      if (totalDemand &lt;= Int.MaxValue) {
        val (use, keep) = buf.splitAt(totalDemand.toInt)
        buf = keep
        use foreach onNext
      } else {
        buf foreach onNext
        buf = Vector.empty
      }
    }
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/xmeng1/akka/tree/master/akka-docs/src/test/java/jdocs/persistence/query/MyEventsByTagJavaPublisher.java#L31-L134" target="_blank" title="Go to snippet source"></a><code class="language-java">class MyEventsByTagJavaPublisher extends AbstractActorPublisher&lt;EventEnvelope&gt; {
  private final Serialization serialization = SerializationExtension.get(getContext().getSystem());

  private final Connection connection;

  private final String tag;

  private final String CONTINUE = &quot;CONTINUE&quot;;
  private final int LIMIT = 1000;
  private long currentOffset;
  private List&lt;EventEnvelope&gt; buf = new LinkedList&lt;&gt;();

  private Cancellable continueTask;

  public MyEventsByTagJavaPublisher(
      Connection connection, String tag, Long offset, Duration refreshInterval) {
    this.connection = connection;
    this.tag = tag;
    this.currentOffset = offset;

    final Scheduler scheduler = getContext().getSystem().scheduler();
    this.continueTask =
        scheduler.schedule(
            refreshInterval,
            refreshInterval,
            getSelf(),
            CONTINUE,
            getContext().getDispatcher(),
            getSelf());
  }

  @Override
  public Receive createReceive() {
    return receiveBuilder()
        .matchEquals(
            CONTINUE,
            (in) -&gt; {
              query();
              deliverBuf();
            })
        .match(
            Cancel.class,
            (in) -&gt; {
              getContext().stop(getSelf());
            })
        .build();
  }

  public static Props props(Connection conn, String tag, Long offset, Duration refreshInterval) {
    return Props.create(
        MyEventsByTagJavaPublisher.class,
        () -&gt; new MyEventsByTagJavaPublisher(conn, tag, offset, refreshInterval));
  }

  @Override
  public void postStop() {
    continueTask.cancel();
  }

  private void query() {
    if (buf.isEmpty()) {
      final String query =
          &quot;SELECT id, persistent_repr &quot;
              + &quot;FROM journal WHERE tag = ? AND id &gt; ? &quot;
              + &quot;ORDER BY id LIMIT ?&quot;;

      try (PreparedStatement s = connection.prepareStatement(query)) {
        s.setString(1, tag);
        s.setLong(2, currentOffset);
        s.setLong(3, LIMIT);
        try (ResultSet rs = s.executeQuery()) {

          final List&lt;Pair&lt;Long, byte[]&gt;&gt; res = new ArrayList&lt;&gt;(LIMIT);
          while (rs.next()) res.add(Pair.create(rs.getLong(1), rs.getBytes(2)));

          if (!res.isEmpty()) {
            currentOffset = res.get(res.size() - 1).first();
          }

          buf =
              res.stream()
                  .map(
                      in -&gt; {
                        final Long id = in.first();
                        final byte[] bytes = in.second();

                        final PersistentRepr p =
                            serialization.deserialize(bytes, PersistentRepr.class).get();

                        return new EventEnvelope(
                            Offset.sequence(id), p.persistenceId(), p.sequenceNr(), p.payload());
                      })
                  .collect(toList());
        }
      } catch (Exception e) {
        onErrorThenStop(e);
      }
    }
  }

  private void deliverBuf() {
    while (totalDemand() &gt; 0 &amp;&amp; !buf.isEmpty()) onNext(buf.remove(0));
  }
}</code></pre></dd>
</dl>
<p>The <code>ReadJournalProvider</code> class must have a constructor with one of these signatures:</p>
<ul>
  <li>constructor with a <code>ExtendedActorSystem</code> parameter, a <code>com.typesafe.config.Config</code> parameter, and a <code>String</code> parameter for the config path</li>
  <li>constructor with a <code>ExtendedActorSystem</code> parameter, and a <code>com.typesafe.config.Config</code> parameter</li>
  <li>constructor with one <code>ExtendedActorSystem</code> parameter</li>
  <li>constructor without parameters</li>
</ul>
<p>The plugin section of the actor system&rsquo;s config will be passed in the config constructor parameter. The config path of the plugin is passed in the <code>String</code> parameter.</p>
<p>If the underlying datastore only supports queries that are completed when they reach the end of the &ldquo;result set&rdquo;, the journal has to submit new queries after a while in order to support &ldquo;infinite&rdquo; event streams that include events stored after the initial query has completed. It is recommended that the plugin use a configuration property named <code>refresh-interval</code> for defining such a refresh interval. </p>
<h2><a href="#scaling-out" name="scaling-out" class="anchor"><span class="anchor-link"></span></a>Scaling out</h2>
<p>In a use case where the number of events are very high, the work needed for each event is high or where resilience is important so that if a node crashes the persistent queries are quickly started on a new node and can resume operations <a href="cluster-sharding.html">Cluster Sharding</a> together with event tagging is an excellent fit to shard events over a cluster.</p>
<p>The <a href="https://www.lagomframework.com">Lagom framework</a>, which is built on top of Akka encodes many of the best practices around this. For more details see <span class="group-java"><a href="https://www.lagomframework.com/documentation/current/java/ES_CQRS.html">Managing Data Persistence</a></span> <span class="group-scala"><a href="https://www.lagomframework.com/documentation/current/scala/ES_CQRS.html">Managing Data Persistence</a></span> and <span class="group-java"><a href="https://www.lagomframework.com/documentation/current/java/PersistentEntity.html">Persistent Entity</a></span> <span class="group-scala"><a href="https://www.lagomframework.com/documentation/current/scala/PersistentEntity.html">Persistent Entity</a></span> in the Lagom documentation.</p>
<h3><a href="#plugin-tck" name="plugin-tck" class="anchor"><span class="anchor-link"></span></a>Plugin TCK</h3>
<p>TODO, not available yet.</p>
</div>
</article>

<div class="row">
<div class="small-12 large-9 column">
<section class="nav-prev-next row">
<div class="nav-prev small-6 column">
<a href="persistence-schema-evolution.html"><i class="icon-prev"></i> <span class="link-prev">Persistence - Schema Evolution</span></a>
</div>
<div class="nav-next small-6 column clearfix">
<a class="float-right" href="persistence-query-leveldb.html">Persistence Query for LevelDB <i class="icon-next"></i></a>
</div>
</section>
</div>
</div>

<div class="source-github row">
Found an error in this documentation? The source code for this page can be found <a href="https://github.com/xmeng1/akka/tree/master/akka-docs-cn/src/main/paradox/persistence-query.md">here</a>.
Please feel free to edit and contribute a pull request.
</div>


<footer class="page-footer row clearfix">
<img class="akka-icon float-left show-for-medium" src="images/akka-icon.svg">
<section class="copyright">
<div>Akka is Open Source and available under the Apache 2 License.</div>
<p class="legal">
&copy; 2011-2019 <a href="https://www.lightbend.com" target="_blank">Lightbend, Inc.</a> | 
<a href="https://www.lightbend.com/legal/licenses" target="_blank">Licenses</a> | 
<a href="https://www.lightbend.com/legal/terms" target="_blank">Terms</a> | 
<a href="https://www.lightbend.com/legal/privacy" target="_blank">Privacy Policy</a> | 
<a href="https://akka.io/cookie/" target="_blank">Cookie Listing</a> | 
<a class="optanon-toggle-display">Cookie Settings</a>
</p>
</section>
</footer>

</section>
</main>

<script type="text/javascript" src="js/scrollsneak.js"></script>
<script type="text/javascript">jQuery(document).foundation();</script>
<script type="text/javascript" src="js/groups.js"></script>
<script type="text/javascript" src="js/page.js"></script>
<script type="text/javascript" src="js/magellan.js"></script>

<style type="text/css">@import "lib/prettify/prettify.css";</style>
<script type="text/javascript" src="lib/prettify/prettify.js"></script>
<script type="text/javascript" src="lib/prettify/lang-scala.js"></script>
<script type="text/javascript">jQuery(function(){window.prettyPrint && prettyPrint()});</script>

<!-- Algolia docs search -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.js"></script>
<style>.algolia-autocomplete { display: block !important }</style>
<script type="text/javascript">
docsearch({
apiKey: '543bad5ad786495d9ccd445ed34ed082',
indexName: 'akka_io',
inputSelector: '#search',
algoliaOptions: {
hitsPerPage: 5
}
});

docsearch({
apiKey: '543bad5ad786495d9ccd445ed34ed082',
indexName: 'akka_io',
inputSelector: '#overlay-search',
algoliaOptions: {
hitsPerPage: 5
}
});

// set up "/" as global shortcut for focusing on search
jQuery(document).keypress(function (event) {
if (event.keyCode == 47) {
jQuery("#search").focus();
return false; // swallow key event, otherwise the / char would be input into the search box
}
});
</script>

<script type="text/javascript" src="assets/js/warnOldDocs.js"></script>
<script type="text/javascript" src="assets/js/scalafiddle.js"></script>


</body>
</html>
